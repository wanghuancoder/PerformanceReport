Container nvidia build =  13409399
XLA activated
--------------------------------------------------------------------------
WARNING: Open MPI tried to bind a process but failed.  This is a
warning only; your job will continue, though performance may
be degraded.

  Local host:        yq01-gpu-255-129-15-00
  Application name:  /usr/bin/python
  Error message:     failed to bind memory
  Location:          rtc_hwloc.c:445

--------------------------------------------------------------------------
2020-12-17 13:26:42.452803: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:26:42.452820: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:26:42.452831: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:26:42.452784: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:26:42.452785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:26:42.452813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:26:42.452797: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:26:42.452790: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 13:26:44.371428 140016424904512 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 13:26:44.371661 140523775752000 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 13:26:44.371798 140561962080064 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 13:26:44.371844 140385729439552 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 13:26:44.371870 139941434881856 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 13:26:44.371867 139971395655488 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 13:26:44.371899 140564319336256 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 13:26:44.372010 140275641628480 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd6b16fb2b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 13:26:45.931974 140561962080064 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd6b16fb2b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd6b16f5a60>) includes params argument, but params are not passed to Estimator.
W1217 13:26:45.932872 140561962080064 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd6b16f5a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fada92702b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4d30ef3400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:***** Configuaration *****
I1217 13:26:45.937116 139971395655488 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4d30ef3400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f94076852b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f4d30eeda60>) includes params argument, but params are not passed to Estimator.
W1217 13:26:45.940334 139971395655488 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f4d30eeda60>) includes params argument, but params are not passed to Estimator.
I1217 13:26:45.939387 140275641628480 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f94076852b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:***** Running training *****
I1217 13:26:45.941040 139971395655488 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 32
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f940767fa60>) includes params argument, but params are not passed to Estimator.
I1217 13:26:45.941258 139971395655488 run_pretraining.py:624]   Batch size = 32
W1217 13:26:45.941245 140275641628480 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f940767fa60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 13:26:45.942690 140275641628480 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 32
I1217 13:26:45.942843 140275641628480 run_pretraining.py:624]   Batch size = 32
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcdcd5a9320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 13:26:45.943548 140523775752000 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcdcd5a9320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:***** Running training *****
I1217 13:26:45.944403 140561962080064 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 32
I1217 13:26:45.944588 140561962080064 run_pretraining.py:624]   Batch size = 32
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fcdcd5a3a60>) includes params argument, but params are not passed to Estimator.
W1217 13:26:45.944651 140523775752000 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fcdcd5a3a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 13:26:45.945345 140523775752000 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 32
I1217 13:26:45.945522 140523775752000 run_pretraining.py:624]   Batch size = 32
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4637221278>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 13:26:45.948587 139941434881856 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4637221278>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f463721aa60>) includes params argument, but params are not passed to Estimator.
W1217 13:26:45.949578 139941434881856 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f463721aa60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 13:26:45.950161 139941434881856 run_pretraining.py:623] ***** Running training *****
I1217 13:26:45.936634 140385729439552 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fada92702b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  Batch size = 32
I1217 13:26:45.950325 139941434881856 run_pretraining.py:624]   Batch size = 32
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fada9269a60>) includes params argument, but params are not passed to Estimator.
W1217 13:26:45.950607 140385729439552 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fada9269a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 13:26:45.938501 140016424904512 run_pretraining.py:577] ***** Configuaration *****
I1217 13:26:45.951335 140385729439552 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  logtostderr: False
I1217 13:26:45.951444 140016424904512 run_pretraining.py:579]   logtostderr: False
INFO:tensorflow:  alsologtostderr: False
I1217 13:26:45.951631 140016424904512 run_pretraining.py:579]   alsologtostderr: False
INFO:tensorflow:  log_dir:
INFO:tensorflow:  Batch size = 32
I1217 13:26:45.951772 140016424904512 run_pretraining.py:579]   log_dir:
INFO:tensorflow:  v: 0
I1217 13:26:45.951506 140385729439552 run_pretraining.py:624]   Batch size = 32
I1217 13:26:45.951874 140016424904512 run_pretraining.py:579]   v: 0
INFO:tensorflow:  verbosity: 0
I1217 13:26:45.952039 140016424904512 run_pretraining.py:579]   verbosity: 0
INFO:tensorflow:  stderrthreshold: fatal
I1217 13:26:45.952166 140016424904512 run_pretraining.py:579]   stderrthreshold: fatal
INFO:tensorflow:  showprefixforinfo: True
I1217 13:26:45.952306 140016424904512 run_pretraining.py:579]   showprefixforinfo: True
INFO:tensorflow:  run_with_pdb: False
I1217 13:26:45.952438 140016424904512 run_pretraining.py:579]   run_with_pdb: False
INFO:tensorflow:  pdb_post_mortem: False
I1217 13:26:45.952566 140016424904512 run_pretraining.py:579]   pdb_post_mortem: False
INFO:tensorflow:  run_with_profiling: False
I1217 13:26:45.952693 140016424904512 run_pretraining.py:579]   run_with_profiling: False
INFO:tensorflow:  profile_file: None
I1217 13:26:45.952819 140016424904512 run_pretraining.py:579]   profile_file: None
INFO:tensorflow:  use_cprofile_for_profiling: True
I1217 13:26:45.952943 140016424904512 run_pretraining.py:579]   use_cprofile_for_profiling: True
INFO:tensorflow:  only_check_args: False
I1217 13:26:45.953078 140016424904512 run_pretraining.py:579]   only_check_args: False
INFO:tensorflow:  op_conversion_fallback_to_while_loop: False
I1217 13:26:45.953204 140016424904512 run_pretraining.py:579]   op_conversion_fallback_to_while_loop: False
INFO:tensorflow:  test_random_seed: 301
I1217 13:26:45.953345 140016424904512 run_pretraining.py:579]   test_random_seed: 301
INFO:tensorflow:  test_srcdir:
I1217 13:26:45.953471 140016424904512 run_pretraining.py:579]   test_srcdir:
INFO:tensorflow:  test_tmpdir: /tmp/absl_testing
I1217 13:26:45.953595 140016424904512 run_pretraining.py:579]   test_tmpdir: /tmp/absl_testing
INFO:tensorflow:  test_randomize_ordering_seed:
I1217 13:26:45.953720 140016424904512 run_pretraining.py:579]   test_randomize_ordering_seed:
INFO:tensorflow:  xml_output_file:
I1217 13:26:45.953846 140016424904512 run_pretraining.py:579]   xml_output_file:
INFO:tensorflow:  bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
I1217 13:26:45.953982 140016424904512 run_pretraining.py:579]   bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
INFO:tensorflow:  input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
I1217 13:26:45.954109 140016424904512 run_pretraining.py:579]   input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
INFO:tensorflow:  eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
I1217 13:26:45.954236 140016424904512 run_pretraining.py:579]   eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
INFO:tensorflow:  output_dir: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1
I1217 13:26:45.954375 140016424904512 run_pretraining.py:579]   output_dir: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1
INFO:tensorflow:  dllog_path: /results/bert_dllog.json
I1217 13:26:45.954500 140016424904512 run_pretraining.py:579]   dllog_path: /results/bert_dllog.json
INFO:tensorflow:  init_checkpoint: None
I1217 13:26:45.954625 140016424904512 run_pretraining.py:579]   init_checkpoint: None
INFO:tensorflow:  optimizer_type: lamb
I1217 13:26:45.954749 140016424904512 run_pretraining.py:579]   optimizer_type: lamb
INFO:tensorflow:  max_seq_length: 128
I1217 13:26:45.954875 140016424904512 run_pretraining.py:579]   max_seq_length: 128
INFO:tensorflow:  max_predictions_per_seq: 20
I1217 13:26:45.955006 140016424904512 run_pretraining.py:579]   max_predictions_per_seq: 20
INFO:tensorflow:  do_train: True
I1217 13:26:45.955132 140016424904512 run_pretraining.py:579]   do_train: True
INFO:tensorflow:  do_eval: True
I1217 13:26:45.955256 140016424904512 run_pretraining.py:579]   do_eval: True
INFO:tensorflow:  train_batch_size: 32
I1217 13:26:45.955394 140016424904512 run_pretraining.py:579]   train_batch_size: 32
INFO:tensorflow:  eval_batch_size: 8
I1217 13:26:45.955519 140016424904512 run_pretraining.py:579]   eval_batch_size: 8
INFO:tensorflow:  learning_rate: 0.00075
I1217 13:26:45.955649 140016424904512 run_pretraining.py:579]   learning_rate: 0.00075
INFO:tensorflow:  num_train_steps: 50
I1217 13:26:45.955774 140016424904512 run_pretraining.py:579]   num_train_steps: 50
INFO:tensorflow:  num_warmup_steps: 2000
I1217 13:26:45.955897 140016424904512 run_pretraining.py:579]   num_warmup_steps: 2000
INFO:tensorflow:  save_checkpoints_steps: 200
I1217 13:26:45.956032 140016424904512 run_pretraining.py:579]   save_checkpoints_steps: 200
INFO:tensorflow:  display_loss_steps: 1
I1217 13:26:45.956157 140016424904512 run_pretraining.py:579]   display_loss_steps: 1
INFO:tensorflow:  iterations_per_loop: 1000
I1217 13:26:45.956289 140016424904512 run_pretraining.py:579]   iterations_per_loop: 1000
INFO:tensorflow:  max_eval_steps: 100
I1217 13:26:45.956416 140016424904512 run_pretraining.py:579]   max_eval_steps: 100
INFO:tensorflow:  num_accumulation_steps: 264
I1217 13:26:45.956539 140016424904512 run_pretraining.py:579]   num_accumulation_steps: 264
INFO:tensorflow:  allreduce_post_accumulation: True
I1217 13:26:45.956665 140016424904512 run_pretraining.py:579]   allreduce_post_accumulation: True
INFO:tensorflow:  verbose_logging: False
I1217 13:26:45.956790 140016424904512 run_pretraining.py:579]   verbose_logging: False
INFO:tensorflow:  horovod: True
I1217 13:26:45.956915 140016424904512 run_pretraining.py:579]   horovod: True
INFO:tensorflow:  report_loss: True
I1217 13:26:45.957047 140016424904512 run_pretraining.py:579]   report_loss: True
INFO:tensorflow:  manual_fp16: False
I1217 13:26:45.957173 140016424904512 run_pretraining.py:579]   manual_fp16: False
INFO:tensorflow:  amp: False
I1217 13:26:45.957306 140016424904512 run_pretraining.py:579]   amp: False
INFO:tensorflow:  use_xla: True
I1217 13:26:45.957434 140016424904512 run_pretraining.py:579]   use_xla: True
INFO:tensorflow:  init_loss_scale: 4294967296
I1217 13:26:45.957559 140016424904512 run_pretraining.py:579]   init_loss_scale: 4294967296
INFO:tensorflow:  ?: False
I1217 13:26:45.957687 140016424904512 run_pretraining.py:579]   ?: False
INFO:tensorflow:  help: False
I1217 13:26:45.957812 140016424904512 run_pretraining.py:579]   help: False
INFO:tensorflow:  helpshort: False
I1217 13:26:45.957938 140016424904512 run_pretraining.py:579]   helpshort: False
INFO:tensorflow:  helpfull: False
I1217 13:26:45.958072 140016424904512 run_pretraining.py:579]   helpfull: False
INFO:tensorflow:  helpxml: False
I1217 13:26:45.958198 140016424904512 run_pretraining.py:579]   helpxml: False
INFO:tensorflow:**************************
I1217 13:26:45.958327 140016424904512 run_pretraining.py:580] **************************
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f57ace30390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 13:26:45.958983 140016424904512 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f57ace30390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f57ace2abf8>) includes params argument, but params are not passed to Estimator.
W1217 13:26:45.959866 140016424904512 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f57ace2abf8>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 13:26:45.960462 140016424904512 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 32
I1217 13:26:45.960611 140016424904512 run_pretraining.py:624]   Batch size = 32
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd73df09320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 13:26:45.985398 140564319336256 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd73df09320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd73df03a60>) includes params argument, but params are not passed to Estimator.
W1217 13:26:45.998747 140564319336256 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd73df03a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 13:26:45.999584 140564319336256 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 32
I1217 13:26:45.999739 140564319336256 run_pretraining.py:624]   Batch size = 32
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 13:26:46.168613 140561962080064 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 13:26:46.189008 139941434881856 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 13:26:46.190163 140385729439552 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 13:26:46.190937 140275641628480 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 13:26:46.185692 139971395655488 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 13:26:46.192654 140523775752000 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 13:26:46.201772 140016424904512 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 13:26:46.239098 140564319336256 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I1217 13:26:46.428907 140561962080064 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 13:26:46.429349 140561962080064 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (32, 128)
I1217 13:26:46.429584 140561962080064 run_pretraining.py:259]   name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
I1217 13:26:46.429769 140561962080064 run_pretraining.py:259]   name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 13:26:46.429964 140561962080064 run_pretraining.py:259]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
I1217 13:26:46.430139 140561962080064 run_pretraining.py:259]   name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
I1217 13:26:46.430319 140561962080064 run_pretraining.py:259]   name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 13:26:46.430492 140561962080064 run_pretraining.py:259]   name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 13:26:46.430658 140561962080064 run_pretraining.py:259]   name = segment_ids, shape = (32, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 13:26:46.431000 140561962080064 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Calling model_fn.
I1217 13:26:46.440709 139971395655488 estimator.py:1148] Calling model_fn.
WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 13:26:46.440939 140561962080064 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

I1217 13:26:46.439179 140523775752000 estimator.py:1148] Calling model_fn.
I1217 13:26:46.437415 140275641628480 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 13:26:46.441117 139971395655488 run_pretraining.py:257] *** Features ***
INFO:tensorflow:*** Features ***
I1217 13:26:46.441204 140275641628480 run_pretraining.py:257] *** Features ***
INFO:tensorflow:*** Features ***
INFO:tensorflow:  name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = input_ids, shape = (32, 128)
I1217 13:26:46.441361 139971395655488 run_pretraining.py:259]   name = input_ids, shape = (32, 128)
I1217 13:26:46.441266 140523775752000 run_pretraining.py:257] *** Features ***
I1217 13:26:46.441360 140275641628480 run_pretraining.py:259]   name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
I1217 13:26:46.441463 139971395655488 run_pretraining.py:259]   name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 13:26:46.441533 140275641628480 run_pretraining.py:259]   name = input_mask, shape = (32, 128)
I1217 13:26:46.441538 139971395655488 run_pretraining.py:259]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 13:26:46.441617 140275641628480 run_pretraining.py:259]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
I1217 13:26:46.441689 140275641628480 run_pretraining.py:259]   name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
I1217 13:26:46.441758 140275641628480 run_pretraining.py:259]   name = masked_lm_weights, shape = (32, 20)
I1217 13:26:46.441646 140523775752000 run_pretraining.py:259]   name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 13:26:46.441725 139971395655488 run_pretraining.py:259]   name = masked_lm_positions, shape = (32, 20)
I1217 13:26:46.441831 140275641628480 run_pretraining.py:259]   name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 13:26:46.441897 140275641628480 run_pretraining.py:259]   name = segment_ids, shape = (32, 128)
I1217 13:26:46.441892 139971395655488 run_pretraining.py:259]   name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 13:26:46.441989 140523775752000 run_pretraining.py:259]   name = input_mask, shape = (32, 128)
I1217 13:26:46.442062 139971395655488 run_pretraining.py:259]   name = next_sentence_labels, shape = (32, 1)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 13:26:46.442181 139971395655488 run_pretraining.py:259]   name = segment_ids, shape = (32, 128)
W1217 13:26:46.442143 140275641628480 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 13:26:46.442274 140523775752000 run_pretraining.py:259]   name = masked_lm_ids, shape = (32, 20)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
W1217 13:26:46.442434 139971395655488 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

I1217 13:26:46.442494 140523775752000 run_pretraining.py:259]   name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
I1217 13:26:46.442696 140523775752000 run_pretraining.py:259]   name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 13:26:46.442865 140523775752000 run_pretraining.py:259]   name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 13:26:46.443044 140523775752000 run_pretraining.py:259]   name = segment_ids, shape = (32, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 13:26:46.443416 140523775752000 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 13:26:46.443736 140275641628480 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 13:26:46.443791 139971395655488 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

I1217 13:26:46.434244 140385729439552 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 13:26:46.447464 140385729439552 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (32, 128)
I1217 13:26:46.447678 140385729439552 run_pretraining.py:259]   name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
I1217 13:26:46.447842 140385729439552 run_pretraining.py:259]   name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 13:26:46.448006 140385729439552 run_pretraining.py:259]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
I1217 13:26:46.448159 140385729439552 run_pretraining.py:259]   name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
I1217 13:26:46.448318 140385729439552 run_pretraining.py:259]   name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 13:26:46.448467 140385729439552 run_pretraining.py:259]   name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 13:26:46.448611 140385729439552 run_pretraining.py:259]   name = segment_ids, shape = (32, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 13:26:46.448926 140385729439552 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 13:26:46.450482 140385729439552 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1217 13:26:46.451423 139941434881856 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 13:26:46.454566 139941434881856 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (32, 128)
I1217 13:26:46.454799 139941434881856 run_pretraining.py:259]   name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
I1217 13:26:46.455008 139941434881856 run_pretraining.py:259]   name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 13:26:46.455190 139941434881856 run_pretraining.py:259]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
I1217 13:26:46.455379 139941434881856 run_pretraining.py:259]   name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
I1217 13:26:46.455551 139941434881856 run_pretraining.py:259]   name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 13:26:46.455726 139941434881856 run_pretraining.py:259]   name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 13:26:46.455900 139941434881856 run_pretraining.py:259]   name = segment_ids, shape = (32, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 13:26:46.456243 139941434881856 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 13:26:46.465005 140523775752000 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 13:26:46.457697 139941434881856 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1217 13:26:46.469117 140016424904512 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 13:26:46.474538 140016424904512 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (32, 128)
I1217 13:26:46.474843 140016424904512 run_pretraining.py:259]   name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
I1217 13:26:46.475049 140016424904512 run_pretraining.py:259]   name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 13:26:46.475227 140016424904512 run_pretraining.py:259]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
I1217 13:26:46.475418 140016424904512 run_pretraining.py:259]   name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
I1217 13:26:46.475593 140016424904512 run_pretraining.py:259]   name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 13:26:46.475759 140016424904512 run_pretraining.py:259]   name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 13:26:46.475923 140016424904512 run_pretraining.py:259]   name = segment_ids, shape = (32, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 13:26:46.476309 140016424904512 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 13:26:46.477708 140016424904512 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1217 13:26:46.523356 140564319336256 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 13:26:46.523675 140564319336256 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (32, 128)
I1217 13:26:46.523872 140564319336256 run_pretraining.py:259]   name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
I1217 13:26:46.524046 140564319336256 run_pretraining.py:259]   name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 13:26:46.524202 140564319336256 run_pretraining.py:259]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
I1217 13:26:46.524375 140564319336256 run_pretraining.py:259]   name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
I1217 13:26:46.524527 140564319336256 run_pretraining.py:259]   name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 13:26:46.524675 140564319336256 run_pretraining.py:259]   name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 13:26:46.524821 140564319336256 run_pretraining.py:259]   name = segment_ids, shape = (32, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 13:26:46.525141 140564319336256 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 13:26:46.526551 140564319336256 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

[yq01-gpu-255-129-15-00.epc.baidu.com:09526] 7 more processes have sent help message help-orte-odls-default.txt / memory not bound
[yq01-gpu-255-129-15-00.epc.baidu.com:09526] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 13:26:49.862009 140523775752000 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 13:26:49.867316 140561962080064 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 13:26:49.889841 140385729439552 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 13:26:49.918686 140275641628480 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 13:26:50.014598 139971395655488 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 13:26:50.104685 140016424904512 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 13:26:50.149344 139941434881856 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 13:26:50.201591 140564319336256 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 13:26:56.150662 139971395655488 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 13:26:56.194677 140561962080064 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 13:26:56.202741 140523775752000 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 13:26:56.302542 140275641628480 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 13:26:56.303835 140385729439552 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 13:26:56.404256 140016424904512 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 13:26:56.495754 139941434881856 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 13:26:56.562265 140564319336256 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I1217 13:27:06.638931 140016424904512 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1217 13:27:06.640509 140016424904512 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Done calling model_fn.
I1217 13:27:10.351381 139971395655488 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 13:27:10.909057 140275641628480 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 13:27:11.004504 140561962080064 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 13:27:11.372936 140564319336256 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 13:27:11.870535 140523775752000 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 13:27:12.164973 139941434881856 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 13:27:13.438926 140385729439552 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Graph was finalized.
I1217 13:27:18.020572 140016424904512 monitored_session.py:240] Graph was finalized.
2020-12-17 13:27:18.041515: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 13:27:18.041832: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6642210 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:18.041894: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 13:27:18.045061: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 13:27:19.494096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:19.498983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6645f80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:19.499103: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 13:27:19.501190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:19.504916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0a.0
2020-12-17 13:27:19.505204: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:19.513917: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:27:19.518108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 13:27:19.519239: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 13:27:19.527963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 13:27:19.529906: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 13:27:19.530753: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:27:19.531250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:19.535085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:19.552203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-12-17 13:27:19.552499: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:20.951415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 13:27:20.951588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-12-17 13:27:20.951635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-12-17 13:27:20.952096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:20.954985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:20.957693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0a.0, compute capability: 7.0)
INFO:tensorflow:Graph was finalized.
I1217 13:27:21.514160 139971395655488 monitored_session.py:240] Graph was finalized.
2020-12-17 13:27:21.539524: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 13:27:21.546411: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x10e03140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:21.546459: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 13:27:21.549544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 13:27:22.031810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:22.037040: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x494cf10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:22.037067: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 13:27:22.038189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:22.042564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0e.0
2020-12-17 13:27:22.042614: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:22.046160: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:27:22.047669: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 13:27:22.048056: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 13:27:22.050965: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 13:27:22.051721: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 13:27:22.052002: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:27:22.052171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:22.067699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:22.073163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 4
2020-12-17 13:27:22.073205: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Graph was finalized.
I1217 13:27:22.240213 140561962080064 monitored_session.py:240] Graph was finalized.
2020-12-17 13:27:22.260610: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 13:27:22.260812: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6046350 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:22.260855: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
I1217 13:27:22.249748 140275641628480 monitored_session.py:240] Graph was finalized.
2020-12-17 13:27:22.263800: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 13:27:22.284489: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 13:27:22.286054: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4abef30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:22.286140: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 13:27:22.291122: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 13:27:22.885049 140564319336256 monitored_session.py:240] Graph was finalized.
2020-12-17 13:27:22.911767: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 13:27:22.912016: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x115a8830 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:22.912031: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 13:27:22.915091: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 13:27:22.983698 140523775752000 monitored_session.py:240] Graph was finalized.
2020-12-17 13:27:23.001648: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 13:27:23.001799: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x11dd9b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:23.001817: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 13:27:23.004852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 13:27:23.286654 139941434881856 monitored_session.py:240] Graph was finalized.
2020-12-17 13:27:23.297802: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 13:27:23.299725: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49b2070 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:23.299776: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 13:27:23.306258: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 13:27:23.471186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 13:27:23.471228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      4
2020-12-17 13:27:23.471239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 4:   N
2020-12-17 13:27:23.473027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:23.484407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:23.495662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0e.0, compute capability: 7.0)
2020-12-17 13:27:23.836453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:23.842651: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5fe1f80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:23.842679: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 13:27:23.844463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:23.847764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:23.848137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0b.0
2020-12-17 13:27:23.848180: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:23.851737: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:27:23.852174: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4ac2ca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:23.852201: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 13:27:23.853045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:23.853214: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 13:27:23.853610: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 13:27:23.856409: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 13:27:23.857081: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 13:27:23.857335: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:27:23.857467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:23.861650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0d.0
2020-12-17 13:27:23.861695: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:23.862464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:23.864940: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:27:23.866358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 1
2020-12-17 13:27:23.866377: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 13:27:23.866407: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:23.866768: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 13:27:23.869632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 13:27:23.870263: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 13:27:23.870522: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:27:23.870659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:23.885654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:23.890438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 3
2020-12-17 13:27:23.890492: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
INFO:tensorflow:Graph was finalized.
I1217 13:27:24.426891 140385729439552 monitored_session.py:240] Graph was finalized.
2020-12-17 13:27:24.465508: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 13:27:24.465672: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12b1ccd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:24.465687: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 13:27:24.468867: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 13:27:24.585420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:24.589305: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5632c80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:24.589335: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 13:27:24.590391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:24.592715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0c.0
2020-12-17 13:27:24.592776: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:24.596487: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:27:24.597990: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 13:27:24.598426: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 13:27:24.601375: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 13:27:24.602043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 13:27:24.602313: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:27:24.602470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:24.615914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:24.621075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 2
2020-12-17 13:27:24.621134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:24.621305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:24.622297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:24.626724: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5892c00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:24.626755: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 13:27:24.627587: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49b5de0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:24.627619: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 13:27:24.628498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:24.628969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:24.661239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0f.0
2020-12-17 13:27:24.661321: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:24.661577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:10.0
2020-12-17 13:27:24.661638: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:24.664803: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:27:24.664785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:27:24.666331: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 13:27:24.666339: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 13:27:24.666731: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 13:27:24.666778: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 13:27:24.669649: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 13:27:24.669638: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 13:27:24.670300: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 13:27:24.670347: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 13:27:24.670610: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:27:24.670683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:27:24.670813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:24.670873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:24.700685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:24.700713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:24.706868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 6
2020-12-17 13:27:24.706928: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:24.706938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 5
2020-12-17 13:27:24.706989: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:25.263489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 13:27:25.263611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      1
2020-12-17 13:27:25.263647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   N
2020-12-17 13:27:25.267557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 13:27:25.267596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      3
2020-12-17 13:27:25.267606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   N
2020-12-17 13:27:25.272090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:25.280584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:25.291611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:25.291621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:25.309410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0b.0, compute capability: 7.0)
2020-12-17 13:27:25.309468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0d.0, compute capability: 7.0)
2020-12-17 13:27:25.685661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:25.706177: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6987e30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 13:27:25.706385: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 13:27:25.708017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:25.724224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:11.0
2020-12-17 13:27:25.724303: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:25.729679: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:27:25.731871: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 13:27:25.732496: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 13:27:25.737147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 13:27:25.738378: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 13:27:25.738693: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:27:25.738892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:25.763331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:25.788996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 7
2020-12-17 13:27:25.789065: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:27:25.907685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 13:27:25.907736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      2
2020-12-17 13:27:25.907746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   N
2020-12-17 13:27:25.917673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:25.929328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:25.935705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 13:27:25.935799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      5
2020-12-17 13:27:25.935985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 5:   N
2020-12-17 13:27:25.952606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:25.954512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0c.0, compute capability: 7.0)
2020-12-17 13:27:25.960397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:25.967637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0f.0, compute capability: 7.0)
2020-12-17 13:27:25.994898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 13:27:25.994949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      6
2020-12-17 13:27:25.994960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 6:   N
2020-12-17 13:27:26.003744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:26.014858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:26.021473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:10.0, compute capability: 7.0)
2020-12-17 13:27:27.190591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 13:27:27.190644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      7
2020-12-17 13:27:27.190655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 7:   N
2020-12-17 13:27:27.191114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:27.192570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:27:27.194027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:11.0, compute capability: 7.0)
2020-12-17 13:27:35.743147: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 13:27:38.364682: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 13:27:40.392774: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 13:27:40.620807: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 13:27:41.120729: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 13:27:41.202271: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 13:27:41.508950: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 13:27:42.536710: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Running local_init_op.
I1217 13:27:46.396919 140016424904512 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 13:27:48.035657 140016424904512 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 13:27:49.198004 139971395655488 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 13:27:50.196911 140561962080064 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 13:27:50.622675 140275641628480 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 13:27:50.659223 139971395655488 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 13:27:51.673480 140561962080064 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 13:27:51.719732 140523775752000 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 13:27:51.963746 139941434881856 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 13:27:52.118425 140275641628480 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 13:27:52.587377 140564319336256 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 13:27:53.306591 140523775752000 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 13:27:53.310418 140385729439552 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 13:27:53.433120 139941434881856 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 13:27:54.084232 140564319336256 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 13:27:54.779589 140385729439552 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1/model.ckpt.
I1217 13:28:10.394885 140016424904512 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1/model.ckpt.
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:146: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W1217 13:28:23.979630 140016424904512 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:146: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2020-12-17 13:29:03.988326: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:29:04.825216: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:29:05.458572: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:29:06.577754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:29:09.774667: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:29:09.860727: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:29:10.033218: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:29:10.237129: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:29:10.478408: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:29:11.373216: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:29:11.415884: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:29:11.642592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:29:11.851065: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:29:12.047612: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:29:12.727258: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:29:14.566123: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:29:40.396208: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 13:29:40.506439: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 13:29:46.649122: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 13:29:47.022935: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 13:29:47.049745: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 13:29:47.156777: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 13:29:47.914577: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 13:29:49.937597: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
INFO:tensorflow:loss = 11.201885, step = 0
I1217 13:29:56.075701 140275641628480 basic_session_run_hooks.py:262] loss = 11.201885, step = 0
INFO:tensorflow:loss = 11.240129, step = 0
I1217 13:29:56.085604 140561962080064 basic_session_run_hooks.py:262] loss = 11.240129, step = 0
INFO:tensorflow:loss = 11.185773, step = 0
I1217 13:30:02.294189 139941434881856 basic_session_run_hooks.py:262] loss = 11.185773, step = 0
INFO:tensorflow:loss = 11.154983, step = 0
I1217 13:30:02.697637 140385729439552 basic_session_run_hooks.py:262] loss = 11.154983, step = 0
INFO:tensorflow:loss = 11.27488, step = 0
I1217 13:30:02.729588 140523775752000 basic_session_run_hooks.py:262] loss = 11.27488, step = 0
INFO:tensorflow:loss = 11.173714, step = 0
I1217 13:30:02.804228 139971395655488 basic_session_run_hooks.py:262] loss = 11.173714, step = 0
INFO:tensorflow:loss = 11.238636, step = 0
I1217 13:30:03.907613 140564319336256 basic_session_run_hooks.py:262] loss = 11.238636, step = 0
INFO:tensorflow:loss = 11.163713, step = 0
I1217 13:30:04.031801 140016424904512 basic_session_run_hooks.py:262] loss = 11.163713, step = 0
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:29.809744 139971395655488 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:29.813452 140275641628480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:29.813531 140561962080064 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:29.822003 139941434881856 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:29.822065 140523775752000 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:29.822232 140385729439552 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:29.822521 140016424904512 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:29.834851 140564319336256 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.085190 140385729439552 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.085187 140564319336256 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.085188 140523775752000 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.085186 140275641628480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.085186 139971395655488 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.085230 140561962080064 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.085647 140016424904512 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.086132 139941434881856 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.330096 139971395655488 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.330072 140561962080064 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.330072 140385729439552 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.330087 140275641628480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.330119 140523775752000 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.330181 140564319336256 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.330208 139941434881856 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.330849 140016424904512 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.594581 139941434881856 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.594566 140561962080064 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.594575 140385729439552 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.594746 140523775752000 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.594718 140016424904512 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.598765 140275641628480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.598968 140564319336256 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.599686 139971395655488 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.843185 139941434881856 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.843193 140523775752000 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.843236 139971395655488 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.843341 140275641628480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.843353 140564319336256 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.843321 140385729439552 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.843726 140561962080064 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 13:31:30.843691 140016424904512 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 13:33:42.398168 - Iteration: 2  throughput_train : 213.403 seq/s mlm_loss : 10.4319  nsp_loss : 0.7392  total_loss : 11.1712  avg_loss_step : 11.2251  learning_rate : 0.0
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 13:34:52.096980 - Iteration: 3  throughput_train : 970.292 seq/s mlm_loss : 10.4916  nsp_loss : 0.7771  total_loss : 11.2687  avg_loss_step : 11.2276  learning_rate : 3e-06
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 13:36:01.144561 - Iteration: 4  throughput_train : 979.470 seq/s mlm_loss : 10.4242  nsp_loss : 0.7756  total_loss : 11.1998  avg_loss_step : 11.2205  learning_rate : 6e-06
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 13:37:10.490154 - Iteration: 5  throughput_train : 975.240 seq/s mlm_loss : 10.4586  nsp_loss : 0.7698  total_loss : 11.2283  avg_loss_step : 11.2222  learning_rate : 9e-06
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 13:38:20.080135 - Iteration: 6  throughput_train : 971.841 seq/s mlm_loss : 10.4171  nsp_loss : 0.7538  total_loss : 11.1709  avg_loss_step : 11.2205  learning_rate : 1.2e-05
DLL 2020-12-17 13:39:29.619638 - Iteration: 7  throughput_train : 972.492 seq/s mlm_loss : 10.4467  nsp_loss : 0.7110  total_loss : 11.1578  avg_loss_step : 11.2132  learning_rate : 1.50000005e-05
DLL 2020-12-17 13:40:39.079007 - Iteration: 8  throughput_train : 973.643 seq/s mlm_loss : 10.4411  nsp_loss : 0.6857  total_loss : 11.1268  avg_loss_step : 11.2040  learning_rate : 1.8e-05
DLL 2020-12-17 13:41:48.634432 - Iteration: 9  throughput_train : 972.326 seq/s mlm_loss : 10.4407  nsp_loss : 0.7557  total_loss : 11.1964  avg_loss_step : 11.1939  learning_rate : 2.1e-05
DLL 2020-12-17 13:42:57.803102 - Iteration: 10  throughput_train : 977.726 seq/s mlm_loss : 10.4298  nsp_loss : 0.7101  total_loss : 11.1399  avg_loss_step : 11.1840  learning_rate : 2.4e-05
DLL 2020-12-17 13:44:07.339154 - Iteration: 11  throughput_train : 972.584 seq/s mlm_loss : 10.4787  nsp_loss : 0.7231  total_loss : 11.2018  avg_loss_step : 11.1710  learning_rate : 2.7000002e-05
DLL 2020-12-17 13:45:16.664675 - Iteration: 12  throughput_train : 975.522 seq/s mlm_loss : 10.4383  nsp_loss : 0.7541  total_loss : 11.1923  avg_loss_step : 11.1611  learning_rate : 3.0000001e-05
DLL 2020-12-17 13:46:26.068372 - Iteration: 13  throughput_train : 974.422 seq/s mlm_loss : 10.3869  nsp_loss : 0.6864  total_loss : 11.0733  avg_loss_step : 11.1468  learning_rate : 3.3e-05
DLL 2020-12-17 13:47:35.222621 - Iteration: 14  throughput_train : 977.954 seq/s mlm_loss : 10.3743  nsp_loss : 0.7161  total_loss : 11.0903  avg_loss_step : 11.1352  learning_rate : 3.6e-05
DLL 2020-12-17 13:48:44.660517 - Iteration: 15  throughput_train : 973.942 seq/s mlm_loss : 10.4191  nsp_loss : 0.6969  total_loss : 11.1160  avg_loss_step : 11.1203  learning_rate : 3.9000002e-05
DLL 2020-12-17 13:49:54.366690 - Iteration: 16  throughput_train : 970.198 seq/s mlm_loss : 10.4150  nsp_loss : 0.6994  total_loss : 11.1145  avg_loss_step : 11.1073  learning_rate : 4.2e-05
DLL 2020-12-17 13:51:04.014239 - Iteration: 17  throughput_train : 971.031 seq/s mlm_loss : 10.3761  nsp_loss : 0.6924  total_loss : 11.0685  avg_loss_step : 11.0930  learning_rate : 4.5e-05
DLL 2020-12-17 13:52:13.294240 - Iteration: 18  throughput_train : 976.149 seq/s mlm_loss : 10.3777  nsp_loss : 0.6836  total_loss : 11.0613  avg_loss_step : 11.0785  learning_rate : 4.8e-05
DLL 2020-12-17 13:53:22.786834 - Iteration: 19  throughput_train : 973.165 seq/s mlm_loss : 10.3610  nsp_loss : 0.6843  total_loss : 11.0452  avg_loss_step : 11.0677  learning_rate : 5.1000003e-05
DLL 2020-12-17 13:54:32.175637 - Iteration: 20  throughput_train : 974.672 seq/s mlm_loss : 10.4326  nsp_loss : 0.6888  total_loss : 11.1215  avg_loss_step : 11.0510  learning_rate : 5.4000004e-05
DLL 2020-12-17 13:55:41.688049 - Iteration: 21  throughput_train : 972.910 seq/s mlm_loss : 10.3954  nsp_loss : 0.7322  total_loss : 11.1277  avg_loss_step : 11.0350  learning_rate : 5.7e-05
DLL 2020-12-17 13:56:51.129327 - Iteration: 22  throughput_train : 973.882 seq/s mlm_loss : 10.3315  nsp_loss : 0.7248  total_loss : 11.0563  avg_loss_step : 11.0273  learning_rate : 6.0000002e-05
DLL 2020-12-17 13:58:00.499631 - Iteration: 23  throughput_train : 974.911 seq/s mlm_loss : 10.2947  nsp_loss : 0.7015  total_loss : 10.9962  avg_loss_step : 11.0074  learning_rate : 6.3e-05
DLL 2020-12-17 13:59:10.080649 - Iteration: 24  throughput_train : 971.960 seq/s mlm_loss : 10.2773  nsp_loss : 0.6700  total_loss : 10.9473  avg_loss_step : 10.9944  learning_rate : 6.6e-05
DLL 2020-12-17 14:00:19.304101 - Iteration: 25  throughput_train : 976.984 seq/s mlm_loss : 10.2906  nsp_loss : 0.7178  total_loss : 11.0083  avg_loss_step : 10.9745  learning_rate : 6.9e-05
DLL 2020-12-17 14:01:28.817201 - Iteration: 26  throughput_train : 972.876 seq/s mlm_loss : 10.2482  nsp_loss : 0.7162  total_loss : 10.9645  avg_loss_step : 10.9590  learning_rate : 7.2e-05
DLL 2020-12-17 14:02:38.330088 - Iteration: 27  throughput_train : 972.893 seq/s mlm_loss : 10.2584  nsp_loss : 0.6664  total_loss : 10.9248  avg_loss_step : 10.9362  learning_rate : 7.5e-05
DLL 2020-12-17 14:03:47.777410 - Iteration: 28  throughput_train : 973.853 seq/s mlm_loss : 10.2218  nsp_loss : 0.7361  total_loss : 10.9578  avg_loss_step : 10.9173  learning_rate : 7.8000005e-05
DLL 2020-12-17 14:04:56.909112 - Iteration: 29  throughput_train : 978.289 seq/s mlm_loss : 10.2433  nsp_loss : 0.6095  total_loss : 10.8528  avg_loss_step : 10.8927  learning_rate : 8.1000006e-05
DLL 2020-12-17 14:06:06.332130 - Iteration: 30  throughput_train : 974.215 seq/s mlm_loss : 10.2171  nsp_loss : 0.6590  total_loss : 10.8761  avg_loss_step : 10.8680  learning_rate : 8.4e-05
DLL 2020-12-17 14:07:15.241988 - Iteration: 31  throughput_train : 981.413 seq/s mlm_loss : 10.2007  nsp_loss : 0.6349  total_loss : 10.8356  avg_loss_step : 10.8475  learning_rate : 8.7e-05
DLL 2020-12-17 14:08:23.913467 - Iteration: 32  throughput_train : 984.813 seq/s mlm_loss : 10.1099  nsp_loss : 0.6787  total_loss : 10.7887  avg_loss_step : 10.8190  learning_rate : 9e-05
DLL 2020-12-17 14:09:32.748442 - Iteration: 33  throughput_train : 982.464 seq/s mlm_loss : 10.1209  nsp_loss : 0.6795  total_loss : 10.8004  avg_loss_step : 10.7937  learning_rate : 9.3e-05
DLL 2020-12-17 14:10:41.710547 - Iteration: 34  throughput_train : 980.726 seq/s mlm_loss : 10.1007  nsp_loss : 0.6995  total_loss : 10.8001  avg_loss_step : 10.7697  learning_rate : 9.6e-05
DLL 2020-12-17 14:11:50.426347 - Iteration: 35  throughput_train : 984.154 seq/s mlm_loss : 10.0574  nsp_loss : 0.6854  total_loss : 10.7427  avg_loss_step : 10.7517  learning_rate : 9.9000004e-05
DLL 2020-12-17 14:12:59.140824 - Iteration: 36  throughput_train : 984.266 seq/s mlm_loss : 10.0635  nsp_loss : 0.6590  total_loss : 10.7226  avg_loss_step : 10.7249  learning_rate : 0.000102000005
DLL 2020-12-17 14:14:07.950450 - Iteration: 37  throughput_train : 982.816 seq/s mlm_loss : 10.0484  nsp_loss : 0.6683  total_loss : 10.7166  avg_loss_step : 10.7034  learning_rate : 0.00010500001
DLL 2020-12-17 14:15:16.490720 - Iteration: 38  throughput_train : 986.737 seq/s mlm_loss : 9.9932  nsp_loss : 0.6817  total_loss : 10.6749  avg_loss_step : 10.6823  learning_rate : 0.00010800001
INFO:tensorflow:loss = 10.656288, step = 37 (2815.813 sec)
INFO:tensorflow:loss = 10.591212, step = 37 (2815.706 sec)
INFO:tensorflow:loss = 10.66547, step = 37 (2814.603 sec)
INFO:tensorflow:loss = 10.676238, step = 37 (2815.781 sec)
INFO:tensorflow:loss = 10.636517, step = 37 (2822.435 sec)
INFO:tensorflow:loss = 10.652098, step = 37 (2816.216 sec)
INFO:tensorflow:loss = 10.668118, step = 37 (2822.425 sec)
I1217 14:16:58.510720 140385729439552 basic_session_run_hooks.py:260] loss = 10.656288, step = 37 (2815.813 sec)
I1217 14:16:58.510709 140523775752000 basic_session_run_hooks.py:260] loss = 10.676238, step = 37 (2815.781 sec)
I1217 14:16:58.510944 140275641628480 basic_session_run_hooks.py:260] loss = 10.636517, step = 37 (2822.435 sec)
I1217 14:16:58.511143 140564319336256 basic_session_run_hooks.py:260] loss = 10.66547, step = 37 (2814.603 sec)
I1217 14:16:58.511105 139941434881856 basic_session_run_hooks.py:260] loss = 10.652098, step = 37 (2816.216 sec)
I1217 14:16:58.511321 140561962080064 basic_session_run_hooks.py:260] loss = 10.668118, step = 37 (2822.425 sec)
I1217 14:16:58.510224 139971395655488 basic_session_run_hooks.py:260] loss = 10.591212, step = 37 (2815.706 sec)
INFO:tensorflow:loss = 10.636436, step = 37 (2814.510 sec)
I1217 14:16:58.542320 140016424904512 basic_session_run_hooks.py:260] loss = 10.636436, step = 37 (2814.510 sec)
DLL 2020-12-17 14:17:06.512264 - Iteration: 39  throughput_train : 614.549 seq/s mlm_loss : 10.0112  nsp_loss : 0.6649  total_loss : 10.6761  avg_loss_step : 10.6593  learning_rate : 0.000111
DLL 2020-12-17 14:18:14.861694 - Iteration: 40  throughput_train : 989.473 seq/s mlm_loss : 9.9441  nsp_loss : 0.6899  total_loss : 10.6340  avg_loss_step : 10.6338  learning_rate : 0.000114
DLL 2020-12-17 14:19:23.418664 - Iteration: 41  throughput_train : 986.465 seq/s mlm_loss : 9.9474  nsp_loss : 0.6937  total_loss : 10.6411  avg_loss_step : 10.6099  learning_rate : 0.000117
DLL 2020-12-17 14:20:32.002483 - Iteration: 42  throughput_train : 986.104 seq/s mlm_loss : 9.9379  nsp_loss : 0.6694  total_loss : 10.6073  avg_loss_step : 10.5827  learning_rate : 0.000120000004
DLL 2020-12-17 14:21:40.453665 - Iteration: 43  throughput_train : 988.005 seq/s mlm_loss : 9.8335  nsp_loss : 0.6585  total_loss : 10.4920  avg_loss_step : 10.5641  learning_rate : 0.000123
DLL 2020-12-17 14:22:49.121605 - Iteration: 44  throughput_train : 984.891 seq/s mlm_loss : 9.8259  nsp_loss : 0.7173  total_loss : 10.5432  avg_loss_step : 10.5395  learning_rate : 0.000126
DLL 2020-12-17 14:23:57.911532 - Iteration: 45  throughput_train : 983.170 seq/s mlm_loss : 9.7995  nsp_loss : 0.6782  total_loss : 10.4777  avg_loss_step : 10.5084  learning_rate : 0.00012900001
DLL 2020-12-17 14:25:06.709392 - Iteration: 46  throughput_train : 982.999 seq/s mlm_loss : 9.7747  nsp_loss : 0.6398  total_loss : 10.4145  avg_loss_step : 10.4922  learning_rate : 0.000132
DLL 2020-12-17 14:26:15.329900 - Iteration: 47  throughput_train : 985.597 seq/s mlm_loss : 9.8336  nsp_loss : 0.6844  total_loss : 10.5180  avg_loss_step : 10.4668  learning_rate : 0.00013500001
DLL 2020-12-17 14:27:24.021229 - Iteration: 48  throughput_train : 984.526 seq/s mlm_loss : 9.7568  nsp_loss : 0.7014  total_loss : 10.4581  avg_loss_step : 10.4482  learning_rate : 0.000138
DLL 2020-12-17 14:28:32.619422 - Iteration: 49  throughput_train : 985.943 seq/s mlm_loss : 9.7340  nsp_loss : 0.6949  total_loss : 10.4288  avg_loss_step : 10.4232  learning_rate : 0.00014100001
DLL 2020-12-17 14:29:41.173919 - Iteration: 50  throughput_train : 986.504 seq/s mlm_loss : 9.6336  nsp_loss : 0.6912  total_loss : 10.3248  avg_loss_step : 10.3984  learning_rate : 0.000144
DLL 2020-12-17 14:30:50.411928 - Iteration: 51  throughput_train : 980.102 seq/s mlm_loss : 9.7258  nsp_loss : 0.6144  total_loss : 10.3402  avg_loss_step : 10.3834  learning_rate : 0.000147
INFO:tensorflow:Saving checkpoints for 50 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1/model.ckpt.
I1217 14:30:50.426756 140016424904512 basic_session_run_hooks.py:606] Saving checkpoints for 50 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 10.317987.
I1217 14:30:52.102838 140523775752000 estimator.py:371] Loss for final step: 10.317987.
INFO:tensorflow:Loss for final step: 10.379785.
I1217 14:30:52.121428 139971395655488 estimator.py:371] Loss for final step: 10.379785.
INFO:tensorflow:Loss for final step: 10.373741.
I1217 14:30:52.124041 140385729439552 estimator.py:371] Loss for final step: 10.373741.
INFO:tensorflow:Loss for final step: 10.269063.
I1217 14:30:52.145554 139941434881856 estimator.py:371] Loss for final step: 10.269063.
INFO:tensorflow:Loss for final step: 10.404522.
I1217 14:30:52.348438 140564319336256 estimator.py:371] Loss for final step: 10.404522.
INFO:tensorflow:Loss for final step: 10.287647.
I1217 14:30:52.387236 140275641628480 estimator.py:371] Loss for final step: 10.287647.
INFO:tensorflow:Loss for final step: 10.408378.
I1217 14:30:52.408007 140561962080064 estimator.py:371] Loss for final step: 10.408378.
INFO:tensorflow:Loss for final step: 10.340159.
I1217 14:30:56.888215 140016424904512 estimator.py:371] Loss for final step: 10.340159.
INFO:tensorflow:-----------------------------
I1217 14:30:56.889993 140016424904512 run_pretraining.py:642] -----------------------------
INFO:tensorflow:Total Training Time = 3850.93 for Sentences = 3379200
I1217 14:30:56.890164 140016424904512 run_pretraining.py:644] Total Training Time = 3850.93 for Sentences = 3379200
INFO:tensorflow:Total Training Time W/O Overhead = 3148.00 for Sentences = 3041280
I1217 14:30:56.890341 140016424904512 run_pretraining.py:646] Total Training Time W/O Overhead = 3148.00 for Sentences = 3041280
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 877.50
I1217 14:30:56.890473 140016424904512 run_pretraining.py:647] Throughput Average (sentences/sec) with overhead = 877.50
INFO:tensorflow:Throughput Average (sentences/sec) = 966.10
I1217 14:30:56.890616 140016424904512 run_pretraining.py:648] Throughput Average (sentences/sec) = 966.10
DLL 2020-12-17 14:30:56.890759 -  throughput_train : 966.100 seq/s
INFO:tensorflow:-----------------------------
I1217 14:30:56.890947 140016424904512 run_pretraining.py:650] -----------------------------
INFO:tensorflow:***** Running evaluation *****
I1217 14:30:56.891111 140016424904512 run_pretraining.py:653] ***** Running evaluation *****
INFO:tensorflow:  Batch size = 8
I1217 14:30:56.891238 140016424904512 run_pretraining.py:654]   Batch size = 8
INFO:tensorflow:Calling model_fn.
I1217 14:30:56.934115 140016424904512 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 14:30:56.934436 140016424904512 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (?, 128)
I1217 14:30:56.934623 140016424904512 run_pretraining.py:259]   name = input_ids, shape = (?, 128)
INFO:tensorflow:  name = input_mask, shape = (?, 128)
I1217 14:30:56.934794 140016424904512 run_pretraining.py:259]   name = input_mask, shape = (?, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (?, 20)
I1217 14:30:56.934944 140016424904512 run_pretraining.py:259]   name = masked_lm_ids, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (?, 20)
I1217 14:30:56.935087 140016424904512 run_pretraining.py:259]   name = masked_lm_positions, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (?, 20)
I1217 14:30:56.935227 140016424904512 run_pretraining.py:259]   name = masked_lm_weights, shape = (?, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (?, 1)
I1217 14:30:56.935385 140016424904512 run_pretraining.py:259]   name = next_sentence_labels, shape = (?, 1)
INFO:tensorflow:  name = segment_ids, shape = (?, 128)
I1217 14:30:56.935528 140016424904512 run_pretraining.py:259]   name = segment_ids, shape = (?, 128)
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:337: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

W1217 14:30:58.583235 140016424904512 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:337: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:341: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

W1217 14:30:58.630251 140016424904512 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:341: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

INFO:tensorflow:Done calling model_fn.
I1217 14:30:58.702883 140016424904512 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-12-17T14:30:58Z
I1217 14:30:58.719139 140016424904512 evaluation.py:255] Starting evaluation at 2020-12-17T14:30:58Z
INFO:tensorflow:Graph was finalized.
I1217 14:30:59.146878 140016424904512 monitored_session.py:240] Graph was finalized.
2020-12-17 14:30:59.147991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 14:30:59.149095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0a.0
2020-12-17 14:30:59.149185: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 14:30:59.149328: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 14:30:59.149386: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 14:30:59.149435: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 14:30:59.149485: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 14:30:59.149538: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 14:30:59.149586: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 14:30:59.149724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 14:30:59.150753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 14:30:59.151699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-12-17 14:30:59.151787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 14:30:59.151821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-12-17 14:30:59.151851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-12-17 14:30:59.151998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 14:30:59.153023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 14:30:59.153987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0a.0, compute capability: 7.0)
INFO:tensorflow:Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1/model.ckpt-50
I1217 14:30:59.155101 140016424904512 saver.py:1284] Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1/model.ckpt-50
INFO:tensorflow:Running local_init_op.
I1217 14:31:00.315898 140016424904512 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 14:31:00.399231 140016424904512 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Evaluation [10/100]
I1217 14:31:07.317884 140016424904512 evaluation.py:167] Evaluation [10/100]
INFO:tensorflow:Evaluation [20/100]
I1217 14:31:07.550238 140016424904512 evaluation.py:167] Evaluation [20/100]
INFO:tensorflow:Evaluation [30/100]
I1217 14:31:07.784553 140016424904512 evaluation.py:167] Evaluation [30/100]
INFO:tensorflow:Evaluation [40/100]
I1217 14:31:08.016083 140016424904512 evaluation.py:167] Evaluation [40/100]
INFO:tensorflow:Evaluation [50/100]
I1217 14:31:08.246931 140016424904512 evaluation.py:167] Evaluation [50/100]
INFO:tensorflow:Evaluation [60/100]
I1217 14:31:08.478492 140016424904512 evaluation.py:167] Evaluation [60/100]
INFO:tensorflow:Evaluation [70/100]
I1217 14:31:08.709563 140016424904512 evaluation.py:167] Evaluation [70/100]
INFO:tensorflow:Evaluation [80/100]
I1217 14:31:08.941071 140016424904512 evaluation.py:167] Evaluation [80/100]
INFO:tensorflow:Evaluation [90/100]
I1217 14:31:09.171257 140016424904512 evaluation.py:167] Evaluation [90/100]
INFO:tensorflow:Evaluation [100/100]
I1217 14:31:09.402828 140016424904512 evaluation.py:167] Evaluation [100/100]
INFO:tensorflow:Finished evaluation at 2020-12-17-14:31:09
I1217 14:31:09.762446 140016424904512 evaluation.py:275] Finished evaluation at 2020-12-17-14:31:09
INFO:tensorflow:Saving dict for global step 50: global_step = 50, loss = 10.335315, masked_lm_accuracy = 0.058620226, masked_lm_loss = 9.634437, next_sentence_accuracy = 0.53, next_sentence_loss = 0.7004009
I1217 14:31:09.763105 140016424904512 estimator.py:2049] Saving dict for global step 50: global_step = 50, loss = 10.335315, masked_lm_accuracy = 0.058620226, masked_lm_loss = 9.634437, next_sentence_accuracy = 0.53, next_sentence_loss = 0.7004009
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1/model.ckpt-50
I1217 14:31:10.542222 140016424904512 estimator.py:2109] Saving 'checkpoint_path' summary for global step 50: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217132641/phase_1/model.ckpt-50
INFO:tensorflow:-----------------------------
I1217 14:31:10.543245 140016424904512 run_pretraining.py:682] -----------------------------
INFO:tensorflow:Total Inference Time = 13.65 for Sentences = 800
I1217 14:31:10.543514 140016424904512 run_pretraining.py:684] Total Inference Time = 13.65 for Sentences = 800
INFO:tensorflow:Total Inference Time W/O Overhead = 2.29 for Sentences = 792
I1217 14:31:10.543661 140016424904512 run_pretraining.py:686] Total Inference Time W/O Overhead = 2.29 for Sentences = 792
INFO:tensorflow:Summary Inference Statistics on EVAL set
I1217 14:31:10.543783 140016424904512 run_pretraining.py:687] Summary Inference Statistics on EVAL set
INFO:tensorflow:Batch size = 8
I1217 14:31:10.543905 140016424904512 run_pretraining.py:688] Batch size = 8
INFO:tensorflow:Sequence Length = 128
I1217 14:31:10.544051 140016424904512 run_pretraining.py:689] Sequence Length = 128
INFO:tensorflow:Precision = fp32
I1217 14:31:10.544177 140016424904512 run_pretraining.py:690] Precision = fp32
INFO:tensorflow:Throughput Average (sentences/sec) = 345.81
I1217 14:31:10.544310 140016424904512 run_pretraining.py:691] Throughput Average (sentences/sec) = 345.81
DLL 2020-12-17 14:31:10.544481 -  throughput_val : 345.8095903643104
INFO:tensorflow:-----------------------------
I1217 14:31:10.544720 140016424904512 run_pretraining.py:693] -----------------------------
INFO:tensorflow:***** Eval results *****
I1217 14:31:10.544924 140016424904512 run_pretraining.py:697] ***** Eval results *****
INFO:tensorflow:  global_step = 50
I1217 14:31:10.545063 140016424904512 run_pretraining.py:699]   global_step = 50
INFO:tensorflow:  loss = 10.335315
I1217 14:31:10.545329 140016424904512 run_pretraining.py:699]   loss = 10.335315
INFO:tensorflow:  masked_lm_accuracy = 0.058620226
I1217 14:31:10.545501 140016424904512 run_pretraining.py:699]   masked_lm_accuracy = 0.058620226
INFO:tensorflow:  masked_lm_loss = 9.634437
I1217 14:31:10.545632 140016424904512 run_pretraining.py:699]   masked_lm_loss = 9.634437
INFO:tensorflow:  next_sentence_accuracy = 0.53
I1217 14:31:10.545761 140016424904512 run_pretraining.py:699]   next_sentence_accuracy = 0.53
INFO:tensorflow:  next_sentence_loss = 0.7004009
I1217 14:31:10.545891 140016424904512 run_pretraining.py:699]   next_sentence_loss = 0.7004009
