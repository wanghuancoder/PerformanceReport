Container nvidia build =  13409399
XLA activated
--------------------------------------------------------------------------
WARNING: Open MPI tried to bind a process but failed.  This is a
warning only; your job will continue, though performance may
be degraded.

  Local host:        yq01-gpu-255-129-15-00
  Application name:  /usr/bin/python
  Error message:     failed to bind memory
  Location:          rtc_hwloc.c:445

--------------------------------------------------------------------------
2020-12-17 12:01:32.319163: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:01:32.319191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:01:32.319186: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:01:32.319171: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:01:32.319201: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:01:32.319178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:01:32.319209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
2020-12-17 12:01:32.708547: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:01:34.882484 140310670698304 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:01:34.882486 140309193365312 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:01:34.882557 140709452666688 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:01:34.882701 140454868457280 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:01:34.882774 139836729370432 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:01:34.882837 140312189900608 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:01:34.882981 140180979930944 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:01:34.882986 140029568649024 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9c2f4d8320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:01:36.406404 140310670698304 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9c2f4d8320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f9c2f4d2a60>) includes params argument, but params are not passed to Estimator.
W1217 12:01:36.407267 140310670698304 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f9c2f4d2a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5abc50a320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:01:36.407369 140029568649024 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5abc50a320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:***** Running training *****
I1217 12:01:36.408176 140310670698304 run_pretraining.py:623] ***** Running training *****
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5abc504a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  Batch size = 48
I1217 12:01:36.408442 140310670698304 run_pretraining.py:624]   Batch size = 48
W1217 12:01:36.408360 140029568649024 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5abc504a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 12:01:36.408988 140029568649024 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 48
I1217 12:01:36.409140 140029568649024 run_pretraining.py:624]   Batch size = 48
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9c89dab438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbdc228b4e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:***** Configuaration *****
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9bd73f3320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:01:36.420591 140180979930944 run_pretraining.py:577] ***** Configuaration *****
I1217 12:01:36.418334 140454868457280 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbdc228b4e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:01:36.422848 140309193365312 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9bd73f3320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  logtostderr: False
I1217 12:01:36.423802 140180979930944 run_pretraining.py:579]   logtostderr: False
INFO:tensorflow:  alsologtostderr: False
I1217 12:01:36.423977 140180979930944 run_pretraining.py:579]   alsologtostderr: False
INFO:tensorflow:  log_dir:
I1217 12:01:36.424115 140180979930944 run_pretraining.py:579]   log_dir:
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f9bd73eda60>) includes params argument, but params are not passed to Estimator.
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fbdc2285a60>) includes params argument, but params are not passed to Estimator.
W1217 12:01:36.423826 140309193365312 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f9bd73eda60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  v: 0
W1217 12:01:36.423846 140454868457280 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fbdc2285a60>) includes params argument, but params are not passed to Estimator.
I1217 12:01:36.424268 140180979930944 run_pretraining.py:579]   v: 0
INFO:tensorflow:***** Running training *****
I1217 12:01:36.424362 140309193365312 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  verbosity: 0
I1217 12:01:36.424396 140180979930944 run_pretraining.py:579]   verbosity: 0
INFO:tensorflow:  stderrthreshold: fatal
I1217 12:01:36.424451 140180979930944 run_pretraining.py:579]   stderrthreshold: fatal
INFO:tensorflow:***** Running training *****
INFO:tensorflow:  showprefixforinfo: True
I1217 12:01:36.424584 140180979930944 run_pretraining.py:579]   showprefixforinfo: True
INFO:tensorflow:  run_with_pdb: False
I1217 12:01:36.424561 140454868457280 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 48
I1217 12:01:36.424642 140180979930944 run_pretraining.py:579]   run_with_pdb: False
INFO:tensorflow:  pdb_post_mortem: False
I1217 12:01:36.424435 140309193365312 run_pretraining.py:624]   Batch size = 48
I1217 12:01:36.424762 140180979930944 run_pretraining.py:579]   pdb_post_mortem: False
INFO:tensorflow:  run_with_profiling: False
I1217 12:01:36.424910 140180979930944 run_pretraining.py:579]   run_with_profiling: False
INFO:tensorflow:  Batch size = 48
INFO:tensorflow:  profile_file: None
I1217 12:01:36.425038 140180979930944 run_pretraining.py:579]   profile_file: None
INFO:tensorflow:  use_cprofile_for_profiling: True
I1217 12:01:36.424710 140454868457280 run_pretraining.py:624]   Batch size = 48
I1217 12:01:36.425095 140180979930944 run_pretraining.py:579]   use_cprofile_for_profiling: True
INFO:tensorflow:  only_check_args: False
I1217 12:01:36.425241 140180979930944 run_pretraining.py:579]   only_check_args: False
INFO:tensorflow:  op_conversion_fallback_to_while_loop: False
I1217 12:01:36.425391 140180979930944 run_pretraining.py:579]   op_conversion_fallback_to_while_loop: False
INFO:tensorflow:  test_random_seed: 301
I1217 12:01:36.425523 140180979930944 run_pretraining.py:579]   test_random_seed: 301
INFO:tensorflow:  test_srcdir:
I1217 12:01:36.425648 140180979930944 run_pretraining.py:579]   test_srcdir:
INFO:tensorflow:  test_tmpdir: /tmp/absl_testing
I1217 12:01:36.425772 140180979930944 run_pretraining.py:579]   test_tmpdir: /tmp/absl_testing
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2dd632c320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:01:36.413158 140312189900608 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9c89dab438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f9c89da5a60>) includes params argument, but params are not passed to Estimator.
W1217 12:01:36.426628 140312189900608 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f9c89da5a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 12:01:36.427371 140312189900608 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 48
I1217 12:01:36.427535 140312189900608 run_pretraining.py:624]   Batch size = 48
INFO:tensorflow:  test_randomize_ordering_seed:
I1217 12:01:36.425565 139836729370432 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2dd632c320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:01:36.438342 140180979930944 run_pretraining.py:579]   test_randomize_ordering_seed:
INFO:tensorflow:  xml_output_file:
I1217 12:01:36.438524 140180979930944 run_pretraining.py:579]   xml_output_file:
INFO:tensorflow:  bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
I1217 12:01:36.438657 140180979930944 run_pretraining.py:579]   bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
INFO:tensorflow:  input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
I1217 12:01:36.438785 140180979930944 run_pretraining.py:579]   input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
INFO:tensorflow:  eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
I1217 12:01:36.438914 140180979930944 run_pretraining.py:579]   eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2dd6326a60>) includes params argument, but params are not passed to Estimator.
W1217 12:01:36.438570 139836729370432 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2dd6326a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  output_dir: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1
I1217 12:01:36.439058 140180979930944 run_pretraining.py:579]   output_dir: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1
INFO:tensorflow:  dllog_path: /results/bert_dllog.json
I1217 12:01:36.439116 140180979930944 run_pretraining.py:579]   dllog_path: /results/bert_dllog.json
INFO:tensorflow:  init_checkpoint: None
INFO:tensorflow:***** Running training *****
I1217 12:01:36.439236 139836729370432 run_pretraining.py:623] ***** Running training *****
I1217 12:01:36.439245 140180979930944 run_pretraining.py:579]   init_checkpoint: None
INFO:tensorflow:  optimizer_type: lamb
I1217 12:01:36.439362 140180979930944 run_pretraining.py:579]   optimizer_type: lamb
INFO:tensorflow:  max_seq_length: 128
I1217 12:01:36.439495 140180979930944 run_pretraining.py:579]   max_seq_length: 128
INFO:tensorflow:  max_predictions_per_seq: 20
I1217 12:01:36.439621 140180979930944 run_pretraining.py:579]   max_predictions_per_seq: 20
INFO:tensorflow:  Batch size = 48
INFO:tensorflow:  do_train: True
I1217 12:01:36.439748 140180979930944 run_pretraining.py:579]   do_train: True
INFO:tensorflow:  do_eval: True
I1217 12:01:36.439405 139836729370432 run_pretraining.py:624]   Batch size = 48
I1217 12:01:36.439804 140180979930944 run_pretraining.py:579]   do_eval: True
INFO:tensorflow:  train_batch_size: 48
I1217 12:01:36.439950 140180979930944 run_pretraining.py:579]   train_batch_size: 48
INFO:tensorflow:  eval_batch_size: 8
I1217 12:01:36.440075 140180979930944 run_pretraining.py:579]   eval_batch_size: 8
INFO:tensorflow:  learning_rate: 0.00075
I1217 12:01:36.440207 140180979930944 run_pretraining.py:579]   learning_rate: 0.00075
INFO:tensorflow:  num_train_steps: 50
I1217 12:01:36.440352 140180979930944 run_pretraining.py:579]   num_train_steps: 50
INFO:tensorflow:  num_warmup_steps: 2000
I1217 12:01:36.440543 140180979930944 run_pretraining.py:579]   num_warmup_steps: 2000
INFO:tensorflow:  save_checkpoints_steps: 200
I1217 12:01:36.440675 140180979930944 run_pretraining.py:579]   save_checkpoints_steps: 200
INFO:tensorflow:  display_loss_steps: 1
I1217 12:01:36.440801 140180979930944 run_pretraining.py:579]   display_loss_steps: 1
INFO:tensorflow:  iterations_per_loop: 1000
I1217 12:01:36.440927 140180979930944 run_pretraining.py:579]   iterations_per_loop: 1000
INFO:tensorflow:  max_eval_steps: 100
I1217 12:01:36.441052 140180979930944 run_pretraining.py:579]   max_eval_steps: 100
INFO:tensorflow:  num_accumulation_steps: 176
I1217 12:01:36.441178 140180979930944 run_pretraining.py:579]   num_accumulation_steps: 176
INFO:tensorflow:  allreduce_post_accumulation: True
I1217 12:01:36.441315 140180979930944 run_pretraining.py:579]   allreduce_post_accumulation: True
INFO:tensorflow:  verbose_logging: False
I1217 12:01:36.441452 140180979930944 run_pretraining.py:579]   verbose_logging: False
INFO:tensorflow:  horovod: True
I1217 12:01:36.441579 140180979930944 run_pretraining.py:579]   horovod: True
INFO:tensorflow:  report_loss: True
I1217 12:01:36.441704 140180979930944 run_pretraining.py:579]   report_loss: True
INFO:tensorflow:  manual_fp16: False
I1217 12:01:36.441828 140180979930944 run_pretraining.py:579]   manual_fp16: False
INFO:tensorflow:  amp: False
I1217 12:01:36.441953 140180979930944 run_pretraining.py:579]   amp: False
INFO:tensorflow:  use_xla: True
I1217 12:01:36.442078 140180979930944 run_pretraining.py:579]   use_xla: True
INFO:tensorflow:  init_loss_scale: 4294967296
I1217 12:01:36.442203 140180979930944 run_pretraining.py:579]   init_loss_scale: 4294967296
INFO:tensorflow:  ?: False
I1217 12:01:36.442349 140180979930944 run_pretraining.py:579]   ?: False
INFO:tensorflow:  help: False
I1217 12:01:36.442477 140180979930944 run_pretraining.py:579]   help: False
INFO:tensorflow:  helpshort: False
I1217 12:01:36.442604 140180979930944 run_pretraining.py:579]   helpshort: False
INFO:tensorflow:  helpfull: False
I1217 12:01:36.442730 140180979930944 run_pretraining.py:579]   helpfull: False
INFO:tensorflow:  helpxml: False
I1217 12:01:36.442857 140180979930944 run_pretraining.py:579]   helpxml: False
INFO:tensorflow:**************************
I1217 12:01:36.442974 140180979930944 run_pretraining.py:580] **************************
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7dfd2172e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:01:36.443661 140180979930944 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7dfd2172e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f7dfd211bf8>) includes params argument, but params are not passed to Estimator.
W1217 12:01:36.444574 140180979930944 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f7dfd211bf8>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 12:01:36.445186 140180979930944 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 48
I1217 12:01:36.445360 140180979930944 run_pretraining.py:624]   Batch size = 48
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff9088f7320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:01:36.450875 140709452666688 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff9088f7320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7ff9088f1a60>) includes params argument, but params are not passed to Estimator.
W1217 12:01:36.451739 140709452666688 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7ff9088f1a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 12:01:36.452190 140709452666688 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 48
I1217 12:01:36.452265 140709452666688 run_pretraining.py:624]   Batch size = 48
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:01:36.651440 140310670698304 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:01:36.660032 140309193365312 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:01:36.661014 140029568649024 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:01:36.665450 139836729370432 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:01:36.666549 140454868457280 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:01:36.666106 140312189900608 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:01:36.685261 140180979930944 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:01:36.710978 140709452666688 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I1217 12:01:36.899315 140310670698304 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 12:01:36.899540 140310670698304 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1217 12:01:36.899655 140310670698304 run_pretraining.py:259]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1217 12:01:36.899738 140310670698304 run_pretraining.py:259]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1217 12:01:36.899814 140310670698304 run_pretraining.py:259]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1217 12:01:36.899887 140310670698304 run_pretraining.py:259]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1217 12:01:36.899958 140310670698304 run_pretraining.py:259]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1217 12:01:36.900027 140310670698304 run_pretraining.py:259]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1217 12:01:36.900095 140310670698304 run_pretraining.py:259]   name = segment_ids, shape = (48, 128)
INFO:tensorflow:Calling model_fn.
I1217 12:01:36.906514 140309193365312 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 12:01:36.906734 140309193365312 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1217 12:01:36.906847 140309193365312 run_pretraining.py:259]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1217 12:01:36.906930 140309193365312 run_pretraining.py:259]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1217 12:01:36.907004 140309193365312 run_pretraining.py:259]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1217 12:01:36.907076 140309193365312 run_pretraining.py:259]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1217 12:01:36.907144 140309193365312 run_pretraining.py:259]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1217 12:01:36.907211 140309193365312 run_pretraining.py:259]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1217 12:01:36.907292 140309193365312 run_pretraining.py:259]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:01:36.907530 140309193365312 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:01:36.908846 140309193365312 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:01:36.900345 140310670698304 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:01:36.914622 140310670698304 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1217 12:01:36.921943 140029568649024 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 12:01:36.922204 140029568649024 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1217 12:01:36.922342 140029568649024 run_pretraining.py:259]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1217 12:01:36.922426 140029568649024 run_pretraining.py:259]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1217 12:01:36.922498 140029568649024 run_pretraining.py:259]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:Calling model_fn.
I1217 12:01:36.922566 140029568649024 run_pretraining.py:259]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1217 12:01:36.922635 140029568649024 run_pretraining.py:259]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1217 12:01:36.922700 140029568649024 run_pretraining.py:259]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1217 12:01:36.922764 140029568649024 run_pretraining.py:259]   name = segment_ids, shape = (48, 128)
I1217 12:01:36.922498 140454868457280 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 12:01:36.922707 140454868457280 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1217 12:01:36.922817 140454868457280 run_pretraining.py:259]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1217 12:01:36.922895 140454868457280 run_pretraining.py:259]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1217 12:01:36.922973 140454868457280 run_pretraining.py:259]   name = masked_lm_ids, shape = (48, 20)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:01:36.922993 140029568649024 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1217 12:01:36.923045 140454868457280 run_pretraining.py:259]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1217 12:01:36.923111 140454868457280 run_pretraining.py:259]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1217 12:01:36.923180 140454868457280 run_pretraining.py:259]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1217 12:01:36.923247 140454868457280 run_pretraining.py:259]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:01:36.923511 140454868457280 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:01:36.924259 140029568649024 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:01:36.924812 140454868457280 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1217 12:01:36.927261 139836729370432 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 12:01:36.927505 139836729370432 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1217 12:01:36.927621 139836729370432 run_pretraining.py:259]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1217 12:01:36.927706 139836729370432 run_pretraining.py:259]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1217 12:01:36.927783 139836729370432 run_pretraining.py:259]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1217 12:01:36.927856 139836729370432 run_pretraining.py:259]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1217 12:01:36.927928 139836729370432 run_pretraining.py:259]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1217 12:01:36.927997 139836729370432 run_pretraining.py:259]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1217 12:01:36.928064 139836729370432 run_pretraining.py:259]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:01:36.928308 139836729370432 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:01:36.929637 139836729370432 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1217 12:01:36.935683 140312189900608 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 12:01:36.935906 140312189900608 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1217 12:01:36.936025 140312189900608 run_pretraining.py:259]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1217 12:01:36.936111 140312189900608 run_pretraining.py:259]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1217 12:01:36.936188 140312189900608 run_pretraining.py:259]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1217 12:01:36.936262 140312189900608 run_pretraining.py:259]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1217 12:01:36.936358 140312189900608 run_pretraining.py:259]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1217 12:01:36.936428 140312189900608 run_pretraining.py:259]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1217 12:01:36.936495 140312189900608 run_pretraining.py:259]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:01:36.936727 140312189900608 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:01:36.938046 140312189900608 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Calling model_fn.
I1217 12:01:36.957403 140709452666688 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 12:01:36.957617 140709452666688 run_pretraining.py:257] *** Features ***
I1217 12:01:36.946294 140180979930944 estimator.py:1148] Calling model_fn.
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1217 12:01:36.957733 140709452666688 run_pretraining.py:259]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1217 12:01:36.957818 140709452666688 run_pretraining.py:259]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1217 12:01:36.957896 140709452666688 run_pretraining.py:259]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:*** Features ***
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1217 12:01:36.957972 140709452666688 run_pretraining.py:259]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1217 12:01:36.958041 140709452666688 run_pretraining.py:259]   name = masked_lm_weights, shape = (48, 20)
I1217 12:01:36.957836 140180979930944 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1217 12:01:36.958112 140709452666688 run_pretraining.py:259]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1217 12:01:36.958178 140709452666688 run_pretraining.py:259]   name = segment_ids, shape = (48, 128)
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1217 12:01:36.958310 140180979930944 run_pretraining.py:259]   name = input_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:01:36.958472 140709452666688 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1217 12:01:36.958492 140180979930944 run_pretraining.py:259]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1217 12:01:36.958712 140180979930944 run_pretraining.py:259]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1217 12:01:36.958873 140180979930944 run_pretraining.py:259]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1217 12:01:36.959030 140180979930944 run_pretraining.py:259]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1217 12:01:36.959183 140180979930944 run_pretraining.py:259]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1217 12:01:36.959351 140180979930944 run_pretraining.py:259]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:01:36.959672 140180979930944 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:01:36.961051 140180979930944 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:01:36.979771 140709452666688 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

[yq01-gpu-255-129-15-00.epc.baidu.com:08322] 7 more processes have sent help message help-orte-odls-default.txt / memory not bound
[yq01-gpu-255-129-15-00.epc.baidu.com:08322] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 12:01:40.607568 140310670698304 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 12:01:40.618734 140029568649024 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
W1217 12:01:40.611071 140454868457280 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 12:01:40.654158 140309193365312 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 12:01:40.688174 139836729370432 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

Initializing LAMB Optimizer
W1217 12:01:40.696418 140180979930944 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

Initializing LAMB Optimizer
W1217 12:01:40.712373 140312189900608 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 12:01:40.800688 140709452666688 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:01:46.111650 140029568649024 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:01:46.127420 140310670698304 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:01:46.273472 139836729370432 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:01:46.326556 140312189900608 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:01:46.536040 140454868457280 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:01:46.811488 140180979930944 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:01:46.835999 140309193365312 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:01:46.906527 140709452666688 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I1217 12:01:57.535212 140029568649024 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 12:01:57.987104 140310670698304 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 12:02:00.714272 140454868457280 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 12:02:01.367412 140180979930944 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1217 12:02:01.381695 140180979930944 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Done calling model_fn.
I1217 12:02:01.687972 139836729370432 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 12:02:01.703548 140709452666688 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 12:02:02.147451 140309193365312 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 12:02:02.226516 140312189900608 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Graph was finalized.
I1217 12:02:08.594448 140029568649024 monitored_session.py:240] Graph was finalized.
2020-12-17 12:02:08.606721: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 12:02:08.606929: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5b8d260 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:08.606973: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 12:02:08.617729: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 12:02:08.965966 140310670698304 monitored_session.py:240] Graph was finalized.
2020-12-17 12:02:08.973587: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 12:02:08.973787: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b09210 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:08.973831: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 12:02:08.977018: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 12:02:09.876591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:09.880099: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5b90fd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:09.880123: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 12:02:09.881011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:09.883623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0b.0
2020-12-17 12:02:09.883668: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:09.887226: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:02:09.888781: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 12:02:09.889170: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 12:02:09.892032: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 12:02:09.892688: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 12:02:09.892932: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:02:09.893066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:09.896663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:09.911821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 1
2020-12-17 12:02:09.911868: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:09.911919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:09.916215: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4a8b110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:09.916245: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 12:02:09.917574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:09.921583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0f.0
2020-12-17 12:02:09.921627: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:09.924792: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:02:09.926225: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 12:02:09.926603: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 12:02:09.929403: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 12:02:09.930060: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 12:02:09.930300: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:02:09.930421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:09.934691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:09.942365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 5
2020-12-17 12:02:09.942405: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:11.027868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 12:02:11.027923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      1
2020-12-17 12:02:11.027935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   N
2020-12-17 12:02:11.028645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:11.045549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:11.063273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0b.0, compute capability: 7.0)
2020-12-17 12:02:11.171699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 12:02:11.171748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      5
2020-12-17 12:02:11.171759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 5:   N
2020-12-17 12:02:11.172121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:11.173529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:11.174809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0f.0, compute capability: 7.0)
INFO:tensorflow:Graph was finalized.
I1217 12:02:11.505164 140454868457280 monitored_session.py:240] Graph was finalized.
2020-12-17 12:02:11.533485: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 12:02:11.533645: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x57d7550 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:11.533660: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 12:02:11.536684: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 12:02:11.958614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:11.960446: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x57db2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:11.960474: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 12:02:11.961076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:11.962355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0e.0
2020-12-17 12:02:11.962400: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:11.965798: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:02:11.967299: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 12:02:11.967690: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 12:02:11.970602: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 12:02:11.971266: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 12:02:11.971524: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:02:11.971661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:11.973028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:11.974272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 4
2020-12-17 12:02:11.974319: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
INFO:tensorflow:Graph was finalized.
I1217 12:02:12.369874 140180979930944 monitored_session.py:240] Graph was finalized.
2020-12-17 12:02:12.394587: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 12:02:12.394758: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x11260e90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:12.394774: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 12:02:12.398163: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 12:02:12.575238 139836729370432 monitored_session.py:240] Graph was finalized.
2020-12-17 12:02:12.589509: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 12:02:12.589691: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6424cc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:12.589716: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 12:02:12.592819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 12:02:12.850234 140709452666688 monitored_session.py:240] Graph was finalized.
2020-12-17 12:02:12.884503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 12:02:12.884665: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5aad6f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:12.884680: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 12:02:12.887737: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 12:02:12.892939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:12.896081: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x553ab60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:12.896110: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 12:02:12.897228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:12.912484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0a.0
2020-12-17 12:02:12.912541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:12.916475: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:02:12.917976: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 12:02:12.918388: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 12:02:12.921448: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 12:02:12.922124: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 12:02:12.922388: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:02:12.922537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:12.934904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:12.937994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-12-17 12:02:12.938038: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
INFO:tensorflow:Graph was finalized.
I1217 12:02:12.938937 140309193365312 monitored_session.py:240] Graph was finalized.
2020-12-17 12:02:12.971479: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 12:02:12.971635: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5f485c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:12.971651: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 12:02:12.974700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 12:02:13.188397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 12:02:13.188448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      4
2020-12-17 12:02:13.188459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 4:   N
2020-12-17 12:02:13.191659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Graph was finalized.
I1217 12:02:13.195919 140312189900608 monitored_session.py:240] Graph was finalized.
2020-12-17 12:02:13.202426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:13.207177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0e.0, compute capability: 7.0)
2020-12-17 12:02:13.208386: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 12:02:13.208545: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x11f40250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:13.208564: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 12:02:13.211710: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 12:02:13.245776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:13.254138: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12876910 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:13.254169: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 12:02:13.255787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:13.260084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0d.0
2020-12-17 12:02:13.260133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:13.263651: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:02:13.265143: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 12:02:13.265584: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 12:02:13.268504: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 12:02:13.269184: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 12:02:13.269453: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:02:13.269611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:13.325160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:13.330749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 3
2020-12-17 12:02:13.330802: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:13.966461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:13.975234: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12499dd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:13.975263: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 12:02:13.976754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:13.985571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0c.0
2020-12-17 12:02:13.985624: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:13.989049: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:02:13.990522: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 12:02:13.990936: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 12:02:13.993710: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 12:02:13.994449: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 12:02:13.994700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:02:13.994854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.015725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.022124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 2
2020-12-17 12:02:14.022175: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:14.248640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 12:02:14.248691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-12-17 12:02:14.248702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-12-17 12:02:14.254287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.254493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.262231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.262714: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ee5900 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:14.262745: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 12:02:14.278859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.297618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0a.0, compute capability: 7.0)
2020-12-17 12:02:14.299478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:10.0
2020-12-17 12:02:14.299539: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:14.303005: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:02:14.304570: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 12:02:14.305025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 12:02:14.307916: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 12:02:14.308657: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 12:02:14.308934: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:02:14.309101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.326405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.341141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 6
2020-12-17 12:02:14.341208: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:14.615848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 12:02:14.615899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      3
2020-12-17 12:02:14.615909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   N
2020-12-17 12:02:14.623103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.628890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.642456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0d.0, compute capability: 7.0)
2020-12-17 12:02:14.768528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.779272: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x11e91330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 12:02:14.779415: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 12:02:14.781207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.809504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:11.0
2020-12-17 12:02:14.809578: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:14.814553: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:02:14.816718: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 12:02:14.817128: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 12:02:14.819922: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 12:02:14.820591: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 12:02:14.820852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:02:14.821014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.833813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:14.855003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 7
2020-12-17 12:02:14.855187: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 12:02:15.335553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 12:02:15.335612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      2
2020-12-17 12:02:15.335623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   N
2020-12-17 12:02:15.336007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:15.337444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:15.338740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0c.0, compute capability: 7.0)
2020-12-17 12:02:15.499622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 12:02:15.499679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      6
2020-12-17 12:02:15.499689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 6:   N
2020-12-17 12:02:15.500066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:15.501487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:15.502774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:10.0, compute capability: 7.0)
2020-12-17 12:02:16.004574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 12:02:16.004631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      7
2020-12-17 12:02:16.004642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 7:   N
2020-12-17 12:02:16.005013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:16.006445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 12:02:16.007736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:11.0, compute capability: 7.0)
2020-12-17 12:02:26.004891: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 12:02:26.049726: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 12:02:28.077509: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 12:02:29.560304: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 12:02:29.787825: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 12:02:30.686699: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 12:02:30.877849: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 12:02:31.318495: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Running local_init_op.
I1217 12:02:36.446485 140310670698304 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:02:36.467066 140029568649024 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:02:37.773464 140310670698304 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:02:37.796465 140029568649024 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:02:37.944360 140454868457280 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:02:39.417847 140454868457280 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:02:40.177758 140180979930944 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:02:40.394652 139836729370432 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:02:41.432294 140309193365312 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:02:41.452860 140312189900608 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:02:41.669654 140180979930944 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:02:41.850155 140709452666688 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:02:41.875440 139836729370432 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:02:42.905441 140309193365312 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:02:42.940909 140312189900608 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:02:43.357659 140709452666688 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1/model.ckpt.
I1217 12:02:59.978856 140180979930944 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1/model.ckpt.
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:146: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W1217 12:03:13.329113 140180979930944 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:146: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2020-12-17 12:03:53.991231: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:03:54.883314: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:03:55.543166: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:03:56.515538: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:04:02.505712: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:04:03.200776: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:04:03.369264: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:04:03.386912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:04:03.846978: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:04:04.034348: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:04:04.195772: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 12:04:04.766227: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:04:04.940537: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:04:04.963750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:04:05.528658: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:04:05.879148: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 12:04:07.724412: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 12:04:36.545793: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 12:04:37.107864: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 12:04:45.522255: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 12:04:46.077167: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 12:04:46.266387: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 12:04:47.105677: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 12:04:48.012528: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
INFO:tensorflow:loss = 11.157006, step = 0
I1217 12:04:52.180707 140312189900608 basic_session_run_hooks.py:262] loss = 11.157006, step = 0
INFO:tensorflow:loss = 11.183917, step = 0
I1217 12:04:52.644786 140454868457280 basic_session_run_hooks.py:262] loss = 11.183917, step = 0
INFO:tensorflow:loss = 11.178641, step = 0
I1217 12:05:01.275667 139836729370432 basic_session_run_hooks.py:262] loss = 11.178641, step = 0
INFO:tensorflow:loss = 11.174588, step = 0
I1217 12:05:01.784868 140309193365312 basic_session_run_hooks.py:262] loss = 11.174588, step = 0
INFO:tensorflow:loss = 11.172681, step = 0
I1217 12:05:02.051057 140310670698304 basic_session_run_hooks.py:262] loss = 11.172681, step = 0
INFO:tensorflow:loss = 11.16165, step = 0
I1217 12:05:02.700538 140180979930944 basic_session_run_hooks.py:262] loss = 11.16165, step = 0
INFO:tensorflow:loss = 11.196757, step = 0
I1217 12:05:02.878799 140029568649024 basic_session_run_hooks.py:262] loss = 11.196757, step = 0
INFO:tensorflow:loss = 11.167515, step = 0
I1217 12:05:04.002643 140709452666688 basic_session_run_hooks.py:262] loss = 11.167515, step = 0
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.077852 140454868457280 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.080906 140709452666688 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.088146 140312189900608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.090016 140310670698304 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.090155 140180979930944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.090111 139836729370432 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.090152 140309193365312 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.101802 140029568649024 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.451346 140309193365312 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.451379 140312189900608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.451343 140310670698304 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.451403 139836729370432 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.451365 140709452666688 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.451786 140454868457280 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.452575 140029568649024 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.453028 140180979930944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.796080 140312189900608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.796077 140454868457280 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.796076 140310670698304 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.796097 140709452666688 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.796091 140029568649024 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.796105 140309193365312 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.796125 139836729370432 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:35.796381 140180979930944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.140424 139836729370432 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.140417 140309193365312 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.140411 140454868457280 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.140408 140310670698304 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.140487 140709452666688 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.140853 140312189900608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.140895 140029568649024 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.140968 140180979930944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.487925 140310670698304 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.487923 140312189900608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.489419 140309193365312 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.489742 140454868457280 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.490041 139836729370432 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.490216 140709452666688 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.490904 140029568649024 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:06:36.491164 140180979930944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 12:08:42.131989 - Iteration: 2  throughput_train : 206.635 seq/s mlm_loss : 10.4988  nsp_loss : 0.7012  total_loss : 11.2000  avg_loss_step : 11.1754  learning_rate : 0.0
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 12:09:45.417524 - Iteration: 3  throughput_train : 1068.522 seq/s mlm_loss : 10.4923  nsp_loss : 0.7053  total_loss : 11.1976  avg_loss_step : 11.1744  learning_rate : 3e-06
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 12:10:48.274100 - Iteration: 4  throughput_train : 1075.736 seq/s mlm_loss : 10.4719  nsp_loss : 0.7139  total_loss : 11.1859  avg_loss_step : 11.1719  learning_rate : 6e-06
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 12:11:51.257689 - Iteration: 5  throughput_train : 1073.601 seq/s mlm_loss : 10.4469  nsp_loss : 0.7072  total_loss : 11.1542  avg_loss_step : 11.1661  learning_rate : 9e-06
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 12:12:54.141596 - Iteration: 6  throughput_train : 1075.284 seq/s mlm_loss : 10.4668  nsp_loss : 0.6877  total_loss : 11.1545  avg_loss_step : 11.1657  learning_rate : 1.2e-05
DLL 2020-12-17 12:13:56.778858 - Iteration: 7  throughput_train : 1079.490 seq/s mlm_loss : 10.4783  nsp_loss : 0.6965  total_loss : 11.1748  avg_loss_step : 11.1626  learning_rate : 1.50000005e-05
DLL 2020-12-17 12:14:59.662890 - Iteration: 8  throughput_train : 1075.276 seq/s mlm_loss : 10.4618  nsp_loss : 0.7106  total_loss : 11.1723  avg_loss_step : 11.1587  learning_rate : 1.8e-05
DLL 2020-12-17 12:16:02.613859 - Iteration: 9  throughput_train : 1074.155 seq/s mlm_loss : 10.4531  nsp_loss : 0.6971  total_loss : 11.1502  avg_loss_step : 11.1536  learning_rate : 2.1e-05
DLL 2020-12-17 12:17:05.638332 - Iteration: 10  throughput_train : 1072.880 seq/s mlm_loss : 10.4488  nsp_loss : 0.7062  total_loss : 11.1551  avg_loss_step : 11.1442  learning_rate : 2.4e-05
DLL 2020-12-17 12:18:08.433076 - Iteration: 11  throughput_train : 1076.817 seq/s mlm_loss : 10.4678  nsp_loss : 0.6997  total_loss : 11.1675  avg_loss_step : 11.1338  learning_rate : 2.7000002e-05
DLL 2020-12-17 12:19:11.219540 - Iteration: 12  throughput_train : 1076.953 seq/s mlm_loss : 10.4394  nsp_loss : 0.6560  total_loss : 11.0953  avg_loss_step : 11.1293  learning_rate : 3.0000001e-05
DLL 2020-12-17 12:20:14.190247 - Iteration: 13  throughput_train : 1073.871 seq/s mlm_loss : 10.4413  nsp_loss : 0.7162  total_loss : 11.1576  avg_loss_step : 11.1204  learning_rate : 3.3e-05
DLL 2020-12-17 12:21:16.884475 - Iteration: 14  throughput_train : 1078.537 seq/s mlm_loss : 10.4450  nsp_loss : 0.6869  total_loss : 11.1319  avg_loss_step : 11.1088  learning_rate : 3.6e-05
DLL 2020-12-17 12:22:19.780674 - Iteration: 15  throughput_train : 1075.067 seq/s mlm_loss : 10.4040  nsp_loss : 0.7046  total_loss : 11.1086  avg_loss_step : 11.0986  learning_rate : 3.9000002e-05
DLL 2020-12-17 12:23:22.479210 - Iteration: 16  throughput_train : 1078.454 seq/s mlm_loss : 10.4177  nsp_loss : 0.6462  total_loss : 11.0639  avg_loss_step : 11.0856  learning_rate : 4.2e-05
DLL 2020-12-17 12:24:25.207477 - Iteration: 17  throughput_train : 1077.993 seq/s mlm_loss : 10.3887  nsp_loss : 0.6857  total_loss : 11.0743  avg_loss_step : 11.0707  learning_rate : 4.5e-05
DLL 2020-12-17 12:25:27.936962 - Iteration: 18  throughput_train : 1077.914 seq/s mlm_loss : 10.3871  nsp_loss : 0.7425  total_loss : 11.1296  avg_loss_step : 11.0552  learning_rate : 4.8e-05
DLL 2020-12-17 12:26:30.671955 - Iteration: 19  throughput_train : 1077.822 seq/s mlm_loss : 10.3933  nsp_loss : 0.6990  total_loss : 11.0923  avg_loss_step : 11.0409  learning_rate : 5.1000003e-05
DLL 2020-12-17 12:27:33.518953 - Iteration: 20  throughput_train : 1075.899 seq/s mlm_loss : 10.3182  nsp_loss : 0.6524  total_loss : 10.9706  avg_loss_step : 11.0210  learning_rate : 5.4000004e-05
DLL 2020-12-17 12:28:36.205737 - Iteration: 21  throughput_train : 1078.657 seq/s mlm_loss : 10.3158  nsp_loss : 0.6174  total_loss : 10.9332  avg_loss_step : 11.0024  learning_rate : 5.7e-05
DLL 2020-12-17 12:29:38.932844 - Iteration: 22  throughput_train : 1077.988 seq/s mlm_loss : 10.2758  nsp_loss : 0.6541  total_loss : 10.9299  avg_loss_step : 10.9902  learning_rate : 6.0000002e-05
DLL 2020-12-17 12:30:41.885995 - Iteration: 23  throughput_train : 1074.092 seq/s mlm_loss : 10.3057  nsp_loss : 0.6593  total_loss : 10.9650  avg_loss_step : 10.9733  learning_rate : 6.3e-05
DLL 2020-12-17 12:31:44.824714 - Iteration: 24  throughput_train : 1074.323 seq/s mlm_loss : 10.2974  nsp_loss : 0.6857  total_loss : 10.9831  avg_loss_step : 10.9486  learning_rate : 6.6e-05
DLL 2020-12-17 12:32:47.589717 - Iteration: 25  throughput_train : 1077.377 seq/s mlm_loss : 10.2374  nsp_loss : 0.6822  total_loss : 10.9196  avg_loss_step : 10.9297  learning_rate : 6.9e-05
DLL 2020-12-17 12:33:50.424892 - Iteration: 26  throughput_train : 1076.105 seq/s mlm_loss : 10.2072  nsp_loss : 0.6892  total_loss : 10.8963  avg_loss_step : 10.9080  learning_rate : 7.2e-05
DLL 2020-12-17 12:34:53.388972 - Iteration: 27  throughput_train : 1073.948 seq/s mlm_loss : 10.2091  nsp_loss : 0.6887  total_loss : 10.8979  avg_loss_step : 10.8808  learning_rate : 7.5e-05
DLL 2020-12-17 12:35:56.306571 - Iteration: 28  throughput_train : 1074.705 seq/s mlm_loss : 10.1858  nsp_loss : 0.6824  total_loss : 10.8682  avg_loss_step : 10.8669  learning_rate : 7.8000005e-05
DLL 2020-12-17 12:36:59.149184 - Iteration: 29  throughput_train : 1075.976 seq/s mlm_loss : 10.1342  nsp_loss : 0.6659  total_loss : 10.8001  avg_loss_step : 10.8374  learning_rate : 8.1000006e-05
DLL 2020-12-17 12:38:01.946906 - Iteration: 30  throughput_train : 1076.750 seq/s mlm_loss : 10.1471  nsp_loss : 0.7009  total_loss : 10.8480  avg_loss_step : 10.8127  learning_rate : 8.4e-05
DLL 2020-12-17 12:39:04.803152 - Iteration: 31  throughput_train : 1075.768 seq/s mlm_loss : 10.1043  nsp_loss : 0.6923  total_loss : 10.7966  avg_loss_step : 10.7919  learning_rate : 8.7e-05
DLL 2020-12-17 12:40:07.673451 - Iteration: 32  throughput_train : 1075.528 seq/s mlm_loss : 10.0546  nsp_loss : 0.6905  total_loss : 10.7451  avg_loss_step : 10.7674  learning_rate : 9e-05
DLL 2020-12-17 12:41:10.565991 - Iteration: 33  throughput_train : 1075.204 seq/s mlm_loss : 10.0640  nsp_loss : 0.6400  total_loss : 10.7040  avg_loss_step : 10.7400  learning_rate : 9.3e-05
DLL 2020-12-17 12:42:13.461415 - Iteration: 34  throughput_train : 1075.084 seq/s mlm_loss : 10.0448  nsp_loss : 0.7019  total_loss : 10.7467  avg_loss_step : 10.7111  learning_rate : 9.6e-05
DLL 2020-12-17 12:43:16.216662 - Iteration: 35  throughput_train : 1077.515 seq/s mlm_loss : 10.0410  nsp_loss : 0.7149  total_loss : 10.7559  avg_loss_step : 10.6886  learning_rate : 9.9000004e-05
DLL 2020-12-17 12:44:18.961451 - Iteration: 36  throughput_train : 1077.656 seq/s mlm_loss : 10.0469  nsp_loss : 0.6374  total_loss : 10.6843  avg_loss_step : 10.6715  learning_rate : 0.000102000005
DLL 2020-12-17 12:45:21.921639 - Iteration: 37  throughput_train : 1073.984 seq/s mlm_loss : 9.9820  nsp_loss : 0.6534  total_loss : 10.6353  avg_loss_step : 10.6388  learning_rate : 0.00010500001
DLL 2020-12-17 12:46:24.777998 - Iteration: 38  throughput_train : 1075.750 seq/s mlm_loss : 9.9068  nsp_loss : 0.6756  total_loss : 10.5824  avg_loss_step : 10.6036  learning_rate : 0.00010800001
DLL 2020-12-17 12:47:27.615309 - Iteration: 39  throughput_train : 1076.075 seq/s mlm_loss : 9.8826  nsp_loss : 0.6916  total_loss : 10.5741  avg_loss_step : 10.5851  learning_rate : 0.000111
DLL 2020-12-17 12:48:30.469511 - Iteration: 40  throughput_train : 1075.793 seq/s mlm_loss : 9.8890  nsp_loss : 0.7159  total_loss : 10.6049  avg_loss_step : 10.5598  learning_rate : 0.000114
DLL 2020-12-17 12:49:33.380799 - Iteration: 41  throughput_train : 1074.805 seq/s mlm_loss : 9.8749  nsp_loss : 0.6307  total_loss : 10.5056  avg_loss_step : 10.5408  learning_rate : 0.000117
DLL 2020-12-17 12:50:36.232529 - Iteration: 42  throughput_train : 1075.869 seq/s mlm_loss : 9.8707  nsp_loss : 0.6783  total_loss : 10.5490  avg_loss_step : 10.5152  learning_rate : 0.000120000004
DLL 2020-12-17 12:51:39.223893 - Iteration: 43  throughput_train : 1073.434 seq/s mlm_loss : 9.8392  nsp_loss : 0.6468  total_loss : 10.4860  avg_loss_step : 10.4906  learning_rate : 0.000123
DLL 2020-12-17 12:52:42.223528 - Iteration: 44  throughput_train : 1073.334 seq/s mlm_loss : 9.7633  nsp_loss : 0.6633  total_loss : 10.4266  avg_loss_step : 10.4649  learning_rate : 0.000126
DLL 2020-12-17 12:53:45.285179 - Iteration: 45  throughput_train : 1072.289 seq/s mlm_loss : 9.8033  nsp_loss : 0.6788  total_loss : 10.4821  avg_loss_step : 10.4444  learning_rate : 0.00012900001
DLL 2020-12-17 12:54:48.249067 - Iteration: 46  throughput_train : 1073.925 seq/s mlm_loss : 9.7544  nsp_loss : 0.6605  total_loss : 10.4149  avg_loss_step : 10.4160  learning_rate : 0.000132
DLL 2020-12-17 12:55:51.135685 - Iteration: 47  throughput_train : 1075.227 seq/s mlm_loss : 9.7148  nsp_loss : 0.6743  total_loss : 10.3891  avg_loss_step : 10.3990  learning_rate : 0.00013500001
DLL 2020-12-17 12:56:54.157938 - Iteration: 48  throughput_train : 1072.945 seq/s mlm_loss : 9.7722  nsp_loss : 0.6871  total_loss : 10.4593  avg_loss_step : 10.3700  learning_rate : 0.000138
DLL 2020-12-17 12:57:56.926599 - Iteration: 49  throughput_train : 1077.249 seq/s mlm_loss : 9.6774  nsp_loss : 0.6911  total_loss : 10.3685  avg_loss_step : 10.3527  learning_rate : 0.00014100001
DLL 2020-12-17 12:58:59.745739 - Iteration: 50  throughput_train : 1076.391 seq/s mlm_loss : 9.6839  nsp_loss : 0.6947  total_loss : 10.3785  avg_loss_step : 10.3255  learning_rate : 0.000144
DLL 2020-12-17 13:00:02.639171 - Iteration: 51  throughput_train : 1077.421 seq/s mlm_loss : 9.6544  nsp_loss : 0.6664  total_loss : 10.3208  avg_loss_step : 10.3060  learning_rate : 0.000147
INFO:tensorflow:Saving checkpoints for 50 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1/model.ckpt.
I1217 13:00:02.641062 140180979930944 basic_session_run_hooks.py:606] Saving checkpoints for 50 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 10.401268.
I1217 13:00:04.333418 139836729370432 estimator.py:371] Loss for final step: 10.401268.
INFO:tensorflow:Loss for final step: 10.182649.
I1217 13:00:04.364072 140309193365312 estimator.py:371] Loss for final step: 10.182649.
INFO:tensorflow:Loss for final step: 10.366665.
I1217 13:00:04.369193 140310670698304 estimator.py:371] Loss for final step: 10.366665.
INFO:tensorflow:Loss for final step: 10.097165.
I1217 13:00:04.374302 140454868457280 estimator.py:371] Loss for final step: 10.097165.
INFO:tensorflow:Loss for final step: 10.302551.
I1217 13:00:04.375339 140029568649024 estimator.py:371] Loss for final step: 10.302551.
INFO:tensorflow:Loss for final step: 10.280092.
I1217 13:00:04.387056 140709452666688 estimator.py:371] Loss for final step: 10.280092.
INFO:tensorflow:Loss for final step: 10.454637.
I1217 13:00:04.389805 140312189900608 estimator.py:371] Loss for final step: 10.454637.
INFO:tensorflow:Loss for final step: 10.320817.
I1217 13:00:08.829464 140180979930944 estimator.py:371] Loss for final step: 10.320817.
INFO:tensorflow:-----------------------------
I1217 13:00:08.831361 140180979930944 run_pretraining.py:642] -----------------------------
INFO:tensorflow:Total Training Time = 3512.39 for Sentences = 3379200
I1217 13:00:08.831537 140180979930944 run_pretraining.py:644] Total Training Time = 3512.39 for Sentences = 3379200
INFO:tensorflow:Total Training Time W/O Overhead = 2826.93 for Sentences = 3041280
I1217 13:00:08.831684 140180979930944 run_pretraining.py:646] Total Training Time W/O Overhead = 2826.93 for Sentences = 3041280
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 962.08
I1217 13:00:08.831815 140180979930944 run_pretraining.py:647] Throughput Average (sentences/sec) with overhead = 962.08
INFO:tensorflow:Throughput Average (sentences/sec) = 1075.83
I1217 13:00:08.831951 140180979930944 run_pretraining.py:648] Throughput Average (sentences/sec) = 1075.83
DLL 2020-12-17 13:00:08.832075 -  throughput_train : 1075.826 seq/s
INFO:tensorflow:-----------------------------
I1217 13:00:08.832256 140180979930944 run_pretraining.py:650] -----------------------------
INFO:tensorflow:***** Running evaluation *****
I1217 13:00:08.832433 140180979930944 run_pretraining.py:653] ***** Running evaluation *****
INFO:tensorflow:  Batch size = 8
I1217 13:00:08.832556 140180979930944 run_pretraining.py:654]   Batch size = 8
INFO:tensorflow:Calling model_fn.
I1217 13:00:08.875896 140180979930944 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 13:00:08.876165 140180979930944 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (?, 128)
I1217 13:00:08.876354 140180979930944 run_pretraining.py:259]   name = input_ids, shape = (?, 128)
INFO:tensorflow:  name = input_mask, shape = (?, 128)
I1217 13:00:08.876521 140180979930944 run_pretraining.py:259]   name = input_mask, shape = (?, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (?, 20)
I1217 13:00:08.876670 140180979930944 run_pretraining.py:259]   name = masked_lm_ids, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (?, 20)
I1217 13:00:08.876825 140180979930944 run_pretraining.py:259]   name = masked_lm_positions, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (?, 20)
I1217 13:00:08.876980 140180979930944 run_pretraining.py:259]   name = masked_lm_weights, shape = (?, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (?, 1)
I1217 13:00:08.877121 140180979930944 run_pretraining.py:259]   name = next_sentence_labels, shape = (?, 1)
INFO:tensorflow:  name = segment_ids, shape = (?, 128)
I1217 13:00:08.877261 140180979930944 run_pretraining.py:259]   name = segment_ids, shape = (?, 128)
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:337: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

W1217 13:00:10.521900 140180979930944 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:337: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:341: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

W1217 13:00:10.568128 140180979930944 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:341: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

INFO:tensorflow:Done calling model_fn.
I1217 13:00:10.641361 140180979930944 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-12-17T13:00:10Z
I1217 13:00:10.658071 140180979930944 evaluation.py:255] Starting evaluation at 2020-12-17T13:00:10Z
INFO:tensorflow:Graph was finalized.
I1217 13:00:11.089008 140180979930944 monitored_session.py:240] Graph was finalized.
2020-12-17 13:00:11.090248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:00:11.092748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0a.0
2020-12-17 13:00:11.092807: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 13:00:11.092873: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 13:00:11.092887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 13:00:11.092899: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 13:00:11.092912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 13:00:11.092928: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 13:00:11.092941: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 13:00:11.093035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:00:11.096327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:00:11.098354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-12-17 13:00:11.098450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 13:00:11.098463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-12-17 13:00:11.098470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-12-17 13:00:11.098669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:00:11.100799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 13:00:11.103156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0a.0, compute capability: 7.0)
INFO:tensorflow:Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1/model.ckpt-50
I1217 13:00:11.104201 140180979930944 saver.py:1284] Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1/model.ckpt-50
INFO:tensorflow:Running local_init_op.
I1217 13:00:12.254661 140180979930944 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 13:00:12.338845 140180979930944 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Evaluation [10/100]
I1217 13:00:19.164940 140180979930944 evaluation.py:167] Evaluation [10/100]
INFO:tensorflow:Evaluation [20/100]
I1217 13:00:19.397200 140180979930944 evaluation.py:167] Evaluation [20/100]
INFO:tensorflow:Evaluation [30/100]
I1217 13:00:19.634094 140180979930944 evaluation.py:167] Evaluation [30/100]
INFO:tensorflow:Evaluation [40/100]
I1217 13:00:19.866729 140180979930944 evaluation.py:167] Evaluation [40/100]
INFO:tensorflow:Evaluation [50/100]
I1217 13:00:20.100955 140180979930944 evaluation.py:167] Evaluation [50/100]
INFO:tensorflow:Evaluation [60/100]
I1217 13:00:20.335961 140180979930944 evaluation.py:167] Evaluation [60/100]
INFO:tensorflow:Evaluation [70/100]
I1217 13:00:20.568909 140180979930944 evaluation.py:167] Evaluation [70/100]
INFO:tensorflow:Evaluation [80/100]
I1217 13:00:20.802334 140180979930944 evaluation.py:167] Evaluation [80/100]
INFO:tensorflow:Evaluation [90/100]
I1217 13:00:21.040601 140180979930944 evaluation.py:167] Evaluation [90/100]
INFO:tensorflow:Evaluation [100/100]
I1217 13:00:21.273391 140180979930944 evaluation.py:167] Evaluation [100/100]
INFO:tensorflow:Finished evaluation at 2020-12-17-13:00:21
I1217 13:00:21.627706 140180979930944 evaluation.py:275] Finished evaluation at 2020-12-17-13:00:21
INFO:tensorflow:Saving dict for global step 50: global_step = 50, loss = 10.269891, masked_lm_accuracy = 0.056722693, masked_lm_loss = 9.571813, next_sentence_accuracy = 0.53, next_sentence_loss = 0.6977665
I1217 13:00:21.628468 140180979930944 estimator.py:2049] Saving dict for global step 50: global_step = 50, loss = 10.269891, masked_lm_accuracy = 0.056722693, masked_lm_loss = 9.571813, next_sentence_accuracy = 0.53, next_sentence_loss = 0.6977665
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1/model.ckpt-50
I1217 13:00:22.413270 140180979930944 estimator.py:2109] Saving 'checkpoint_path' summary for global step 50: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_201217120131/phase_1/model.ckpt-50
INFO:tensorflow:-----------------------------
I1217 13:00:22.414487 140180979930944 run_pretraining.py:682] -----------------------------
INFO:tensorflow:Total Inference Time = 13.58 for Sentences = 800
I1217 13:00:22.414725 140180979930944 run_pretraining.py:684] Total Inference Time = 13.58 for Sentences = 800
INFO:tensorflow:Total Inference Time W/O Overhead = 2.32 for Sentences = 792
I1217 13:00:22.414868 140180979930944 run_pretraining.py:686] Total Inference Time W/O Overhead = 2.32 for Sentences = 792
INFO:tensorflow:Summary Inference Statistics on EVAL set
I1217 13:00:22.414991 140180979930944 run_pretraining.py:687] Summary Inference Statistics on EVAL set
INFO:tensorflow:Batch size = 8
I1217 13:00:22.415112 140180979930944 run_pretraining.py:688] Batch size = 8
INFO:tensorflow:Sequence Length = 128
I1217 13:00:22.415267 140180979930944 run_pretraining.py:689] Sequence Length = 128
INFO:tensorflow:Precision = fp32
I1217 13:00:22.415416 140180979930944 run_pretraining.py:690] Precision = fp32
INFO:tensorflow:Throughput Average (sentences/sec) = 342.10
I1217 13:00:22.415534 140180979930944 run_pretraining.py:691] Throughput Average (sentences/sec) = 342.10
DLL 2020-12-17 13:00:22.415667 -  throughput_val : 342.10214160845914
INFO:tensorflow:-----------------------------
I1217 13:00:22.415873 140180979930944 run_pretraining.py:693] -----------------------------
INFO:tensorflow:***** Eval results *****
I1217 13:00:22.416059 140180979930944 run_pretraining.py:697] ***** Eval results *****
INFO:tensorflow:  global_step = 50
I1217 13:00:22.416191 140180979930944 run_pretraining.py:699]   global_step = 50
INFO:tensorflow:  loss = 10.269891
I1217 13:00:22.416433 140180979930944 run_pretraining.py:699]   loss = 10.269891
INFO:tensorflow:  masked_lm_accuracy = 0.056722693
I1217 13:00:22.416581 140180979930944 run_pretraining.py:699]   masked_lm_accuracy = 0.056722693
INFO:tensorflow:  masked_lm_loss = 9.571813
I1217 13:00:22.416726 140180979930944 run_pretraining.py:699]   masked_lm_loss = 9.571813
INFO:tensorflow:  next_sentence_accuracy = 0.53
I1217 13:00:22.416848 140180979930944 run_pretraining.py:699]   next_sentence_accuracy = 0.53
INFO:tensorflow:  next_sentence_loss = 0.6977665
I1217 13:00:22.416969 140180979930944 run_pretraining.py:699]   next_sentence_loss = 0.6977665
