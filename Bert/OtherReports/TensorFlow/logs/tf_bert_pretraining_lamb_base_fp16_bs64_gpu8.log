Container nvidia build =  13409399
XLA activated
--------------------------------------------------------------------------
WARNING: Open MPI tried to bind a process but failed.  This is a
warning only; your job will continue, though performance may
be degraded.

  Local host:        yq01-gpu-255-129-15-00
  Application name:  /usr/bin/python
  Error message:     failed to bind memory
  Location:          rtc_hwloc.c:445

--------------------------------------------------------------------------
2020-12-17 10:30:10.709747: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:10.709741: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:10.709758: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:10.709714: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:10.709779: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:10.709764: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:10.709769: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
2020-12-17 10:30:11.159949: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 10:30:13.136483 140133942306624 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 10:30:13.136991 139737462470464 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 10:30:13.137015 140216016906048 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 10:30:13.137065 139642239878976 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 10:30:13.137231 140601683785536 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 10:30:13.137222 140535237592896 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 10:30:13.137290 139917790811968 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 10:30:13.138298 140452977420096 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 10:30:14.654130 140601683785536 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdff108d2b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 10:30:14.654870 140601683785536 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdff108d2b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fdff1086a60>) includes params argument, but params are not passed to Estimator.
W1217 10:30:14.655657 140601683785536 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fdff1086a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 10:30:14.656084 140601683785536 run_pretraining.py:623] ***** Running training *****
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 10:30:14.664888 140452977420096 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbd5171c358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 10:30:14.665609 140452977420096 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbd5171c358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fbd51715a60>) includes params argument, but params are not passed to Estimator.
W1217 10:30:14.666380 140452977420096 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fbd51715a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 10:30:14.666819 140452977420096 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 64
I1217 10:30:14.666895 140452977420096 run_pretraining.py:624]   Batch size = 64
INFO:tensorflow:  Batch size = 64
I1217 10:30:14.656160 140601683785536 run_pretraining.py:624]   Batch size = 64
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 10:30:14.670043 139737462470464 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f16b96e12b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 10:30:14.670812 139737462470464 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f16b96e12b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f16b96daa60>) includes params argument, but params are not passed to Estimator.
W1217 10:30:14.671774 139737462470464 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f16b96daa60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 10:30:14.672204 139737462470464 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 64
I1217 10:30:14.672291 139737462470464 run_pretraining.py:624]   Batch size = 64
INFO:tensorflow:***** Configuaration *****
I1217 10:30:14.674903 139642239878976 run_pretraining.py:577] ***** Configuaration *****
INFO:tensorflow:  logtostderr: False
I1217 10:30:14.675179 139642239878976 run_pretraining.py:579]   logtostderr: False
INFO:tensorflow:  alsologtostderr: False
I1217 10:30:14.675260 139642239878976 run_pretraining.py:579]   alsologtostderr: False
INFO:tensorflow:  log_dir:
I1217 10:30:14.675352 139642239878976 run_pretraining.py:579]   log_dir:
INFO:tensorflow:  v: 0
I1217 10:30:14.675416 139642239878976 run_pretraining.py:579]   v: 0
INFO:tensorflow:  verbosity: 0
I1217 10:30:14.675477 139642239878976 run_pretraining.py:579]   verbosity: 0
INFO:tensorflow:  stderrthreshold: fatal
I1217 10:30:14.675535 139642239878976 run_pretraining.py:579]   stderrthreshold: fatal
INFO:tensorflow:  showprefixforinfo: True
I1217 10:30:14.675591 139642239878976 run_pretraining.py:579]   showprefixforinfo: True
INFO:tensorflow:  run_with_pdb: False
I1217 10:30:14.675648 139642239878976 run_pretraining.py:579]   run_with_pdb: False
INFO:tensorflow:  pdb_post_mortem: False
I1217 10:30:14.675704 139642239878976 run_pretraining.py:579]   pdb_post_mortem: False
INFO:tensorflow:  run_with_profiling: False
I1217 10:30:14.675759 139642239878976 run_pretraining.py:579]   run_with_profiling: False
INFO:tensorflow:  profile_file: None
I1217 10:30:14.675816 139642239878976 run_pretraining.py:579]   profile_file: None
INFO:tensorflow:  use_cprofile_for_profiling: True
I1217 10:30:14.675871 139642239878976 run_pretraining.py:579]   use_cprofile_for_profiling: True
INFO:tensorflow:  only_check_args: False
I1217 10:30:14.675927 139642239878976 run_pretraining.py:579]   only_check_args: False
INFO:tensorflow:  op_conversion_fallback_to_while_loop: False
I1217 10:30:14.675984 139642239878976 run_pretraining.py:579]   op_conversion_fallback_to_while_loop: False
INFO:tensorflow:  test_random_seed: 301
I1217 10:30:14.676041 139642239878976 run_pretraining.py:579]   test_random_seed: 301
INFO:tensorflow:  test_srcdir:
I1217 10:30:14.676096 139642239878976 run_pretraining.py:579]   test_srcdir:
INFO:tensorflow:  test_tmpdir: /tmp/absl_testing
I1217 10:30:14.676151 139642239878976 run_pretraining.py:579]   test_tmpdir: /tmp/absl_testing
INFO:tensorflow:  test_randomize_ordering_seed:
I1217 10:30:14.676205 139642239878976 run_pretraining.py:579]   test_randomize_ordering_seed:
INFO:tensorflow:  xml_output_file:
I1217 10:30:14.676260 139642239878976 run_pretraining.py:579]   xml_output_file:
INFO:tensorflow:  bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
I1217 10:30:14.676332 139642239878976 run_pretraining.py:579]   bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
INFO:tensorflow:  input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
I1217 10:30:14.676390 139642239878976 run_pretraining.py:579]   input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
INFO:tensorflow:  eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
I1217 10:30:14.676448 139642239878976 run_pretraining.py:579]   eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
INFO:tensorflow:  output_dir: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1
I1217 10:30:14.676505 139642239878976 run_pretraining.py:579]   output_dir: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1
INFO:tensorflow:  dllog_path: /results/bert_dllog.json
I1217 10:30:14.676561 139642239878976 run_pretraining.py:579]   dllog_path: /results/bert_dllog.json
INFO:tensorflow:  init_checkpoint: None
I1217 10:30:14.676616 139642239878976 run_pretraining.py:579]   init_checkpoint: None
INFO:tensorflow:  optimizer_type: lamb
I1217 10:30:14.676671 139642239878976 run_pretraining.py:579]   optimizer_type: lamb
INFO:tensorflow:  max_seq_length: 128
I1217 10:30:14.676726 139642239878976 run_pretraining.py:579]   max_seq_length: 128
INFO:tensorflow:  max_predictions_per_seq: 20
I1217 10:30:14.676780 139642239878976 run_pretraining.py:579]   max_predictions_per_seq: 20
INFO:tensorflow:  do_train: True
I1217 10:30:14.676835 139642239878976 run_pretraining.py:579]   do_train: True
INFO:tensorflow:  do_eval: True
I1217 10:30:14.676889 139642239878976 run_pretraining.py:579]   do_eval: True
INFO:tensorflow:  train_batch_size: 64
I1217 10:30:14.676944 139642239878976 run_pretraining.py:579]   train_batch_size: 64
INFO:tensorflow:  eval_batch_size: 8
I1217 10:30:14.676998 139642239878976 run_pretraining.py:579]   eval_batch_size: 8
INFO:tensorflow:  learning_rate: 0.00075
I1217 10:30:14.677059 139642239878976 run_pretraining.py:579]   learning_rate: 0.00075
INFO:tensorflow:  num_train_steps: 50
I1217 10:30:14.677114 139642239878976 run_pretraining.py:579]   num_train_steps: 50
INFO:tensorflow:  num_warmup_steps: 2000
I1217 10:30:14.677169 139642239878976 run_pretraining.py:579]   num_warmup_steps: 2000
INFO:tensorflow:  save_checkpoints_steps: 200
I1217 10:30:14.677223 139642239878976 run_pretraining.py:579]   save_checkpoints_steps: 200
INFO:tensorflow:  display_loss_steps: 1
I1217 10:30:14.677285 139642239878976 run_pretraining.py:579]   display_loss_steps: 1
INFO:tensorflow:  iterations_per_loop: 1000
I1217 10:30:14.677349 139642239878976 run_pretraining.py:579]   iterations_per_loop: 1000
INFO:tensorflow:  max_eval_steps: 100
I1217 10:30:14.677404 139642239878976 run_pretraining.py:579]   max_eval_steps: 100
INFO:tensorflow:  num_accumulation_steps: 132
I1217 10:30:14.677458 139642239878976 run_pretraining.py:579]   num_accumulation_steps: 132
INFO:tensorflow:  allreduce_post_accumulation: True
I1217 10:30:14.677512 139642239878976 run_pretraining.py:579]   allreduce_post_accumulation: True
INFO:tensorflow:  verbose_logging: False
I1217 10:30:14.677567 139642239878976 run_pretraining.py:579]   verbose_logging: False
INFO:tensorflow:  horovod: True
I1217 10:30:14.677620 139642239878976 run_pretraining.py:579]   horovod: True
INFO:tensorflow:  report_loss: True
I1217 10:30:14.677675 139642239878976 run_pretraining.py:579]   report_loss: True
INFO:tensorflow:  manual_fp16: False
I1217 10:30:14.677730 139642239878976 run_pretraining.py:579]   manual_fp16: False
INFO:tensorflow:  amp: True
I1217 10:30:14.677784 139642239878976 run_pretraining.py:579]   amp: True
INFO:tensorflow:  use_xla: True
I1217 10:30:14.677839 139642239878976 run_pretraining.py:579]   use_xla: True
INFO:tensorflow:  init_loss_scale: 4294967296
I1217 10:30:14.677893 139642239878976 run_pretraining.py:579]   init_loss_scale: 4294967296
INFO:tensorflow:  ?: False
I1217 10:30:14.677948 139642239878976 run_pretraining.py:579]   ?: False
INFO:tensorflow:  help: False
I1217 10:30:14.678002 139642239878976 run_pretraining.py:579]   help: False
INFO:tensorflow:  helpshort: False
I1217 10:30:14.678058 139642239878976 run_pretraining.py:579]   helpshort: False
INFO:tensorflow:  helpfull: False
I1217 10:30:14.678113 139642239878976 run_pretraining.py:579]   helpfull: False
INFO:tensorflow:  helpxml: False
I1217 10:30:14.678168 139642239878976 run_pretraining.py:579]   helpxml: False
INFO:tensorflow:**************************
I1217 10:30:14.678216 139642239878976 run_pretraining.py:580] **************************
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 10:30:14.678390 139642239878976 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f008db8a438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 10:30:14.678930 139642239878976 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f008db8a438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 10:30:14.679647 140535237592896 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f008db84bf8>) includes params argument, but params are not passed to Estimator.
W1217 10:30:14.679692 139642239878976 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f008db84bf8>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 10:30:14.680143 139642239878976 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 64
I1217 10:30:14.680218 139642239878976 run_pretraining.py:624]   Batch size = 64
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd0788864e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 10:30:14.680362 140535237592896 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd0788864e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd078880a60>) includes params argument, but params are not passed to Estimator.
W1217 10:30:14.681114 140535237592896 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd078880a60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 10:30:14.681557 140535237592896 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 64
I1217 10:30:14.681634 140535237592896 run_pretraining.py:624]   Batch size = 64
W1217 10:30:14.671937 140133942306624 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f73097844e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 10:30:14.683088 140133942306624 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f73097844e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f730977ea60>) includes params argument, but params are not passed to Estimator.
W1217 10:30:14.683897 140133942306624 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f730977ea60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 10:30:14.684347 140133942306624 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 64
I1217 10:30:14.684427 140133942306624 run_pretraining.py:624]   Batch size = 64
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 10:30:14.688257 139917790811968 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f40b5d63358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 10:30:14.688987 139917790811968 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f40b5d63358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1217 10:30:14.689762 140216016906048 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f40b5d5da60>) includes params argument, but params are not passed to Estimator.
W1217 10:30:14.689767 139917790811968 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f40b5d5da60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 10:30:14.690187 139917790811968 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f86257f4320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 10:30:14.690471 140216016906048 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f86257f4320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f86257eea60>) includes params argument, but params are not passed to Estimator.
W1217 10:30:14.691223 140216016906048 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f86257eea60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 10:30:14.691678 140216016906048 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 64
I1217 10:30:14.691755 140216016906048 run_pretraining.py:624]   Batch size = 64
INFO:tensorflow:  Batch size = 64
I1217 10:30:14.690263 139917790811968 run_pretraining.py:624]   Batch size = 64
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 10:30:14.902733 140601683785536 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 10:30:14.917077 140452977420096 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 10:30:14.919856 140133942306624 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 10:30:14.927388 139737462470464 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 10:30:14.933340 139917790811968 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 10:30:14.933370 139642239878976 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 10:30:14.935349 140535237592896 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 10:30:14.935765 140216016906048 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I1217 10:30:15.152582 140601683785536 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 10:30:15.152919 140601683785536 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1217 10:30:15.153034 140601683785536 run_pretraining.py:259]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1217 10:30:15.153124 140601683785536 run_pretraining.py:259]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1217 10:30:15.153203 140601683785536 run_pretraining.py:259]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1217 10:30:15.153300 140601683785536 run_pretraining.py:259]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1217 10:30:15.153381 140601683785536 run_pretraining.py:259]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1217 10:30:15.153454 140601683785536 run_pretraining.py:259]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1217 10:30:15.153525 140601683785536 run_pretraining.py:259]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 10:30:15.153760 140601683785536 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 10:30:15.155029 140601683785536 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1217 10:30:15.163836 140452977420096 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 10:30:15.164063 140452977420096 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1217 10:30:15.164183 140452977420096 run_pretraining.py:259]   name = input_ids, shape = (64, 128)
INFO:tensorflow:Calling model_fn.
I1217 10:30:15.166967 139737462470464 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 10:30:15.167392 139737462470464 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1217 10:30:15.167516 139737462470464 run_pretraining.py:259]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1217 10:30:15.167603 139737462470464 run_pretraining.py:259]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1217 10:30:15.167682 139737462470464 run_pretraining.py:259]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1217 10:30:15.167886 139737462470464 run_pretraining.py:259]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1217 10:30:15.167961 139737462470464 run_pretraining.py:259]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1217 10:30:15.168027 139737462470464 run_pretraining.py:259]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1217 10:30:15.168099 139737462470464 run_pretraining.py:259]   name = segment_ids, shape = (64, 128)
I1217 10:30:15.164271 140452977420096 run_pretraining.py:259]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

I1217 10:30:15.168473 140452977420096 run_pretraining.py:259]   name = masked_lm_ids, shape = (64, 20)
W1217 10:30:15.168499 139737462470464 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1217 10:30:15.168606 140452977420096 run_pretraining.py:259]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1217 10:30:15.168733 140452977420096 run_pretraining.py:259]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1217 10:30:15.168889 140452977420096 run_pretraining.py:259]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1217 10:30:15.169040 140452977420096 run_pretraining.py:259]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 10:30:15.169903 139737462470464 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Calling model_fn.
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 10:30:15.182305 140452977420096 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

I1217 10:30:15.181351 139917790811968 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 10:30:15.182649 139917790811968 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1217 10:30:15.182885 139917790811968 run_pretraining.py:259]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1217 10:30:15.183055 139917790811968 run_pretraining.py:259]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1217 10:30:15.183212 139917790811968 run_pretraining.py:259]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1217 10:30:15.183390 139917790811968 run_pretraining.py:259]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1217 10:30:15.183548 139917790811968 run_pretraining.py:259]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1217 10:30:15.183698 139917790811968 run_pretraining.py:259]   name = next_sentence_labels, shape = (64, 1)
WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 10:30:15.183747 140452977420096 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1217 10:30:15.183909 139917790811968 run_pretraining.py:259]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 10:30:15.184234 139917790811968 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 10:30:15.185655 139917790811968 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

I1217 10:30:15.175977 140133942306624 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 10:30:15.188471 140133942306624 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1217 10:30:15.188721 140133942306624 run_pretraining.py:259]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1217 10:30:15.188879 140133942306624 run_pretraining.py:259]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1217 10:30:15.189043 140133942306624 run_pretraining.py:259]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1217 10:30:15.189201 140133942306624 run_pretraining.py:259]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1217 10:30:15.189378 140133942306624 run_pretraining.py:259]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1217 10:30:15.189535 140133942306624 run_pretraining.py:259]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1217 10:30:15.189688 140133942306624 run_pretraining.py:259]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 10:30:15.190016 140133942306624 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 10:30:15.191457 140133942306624 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

I1217 10:30:15.179569 139642239878976 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 10:30:15.192490 139642239878976 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1217 10:30:15.192712 139642239878976 run_pretraining.py:259]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1217 10:30:15.192880 139642239878976 run_pretraining.py:259]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1217 10:30:15.193036 139642239878976 run_pretraining.py:259]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1217 10:30:15.193188 139642239878976 run_pretraining.py:259]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1217 10:30:15.193362 139642239878976 run_pretraining.py:259]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1217 10:30:15.193518 139642239878976 run_pretraining.py:259]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1217 10:30:15.193667 139642239878976 run_pretraining.py:259]   name = segment_ids, shape = (64, 128)
I1217 10:30:15.193588 140216016906048 estimator.py:1148] Calling model_fn.
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:*** Features ***
I1217 10:30:15.193914 140216016906048 run_pretraining.py:257] *** Features ***
W1217 10:30:15.193914 139642239878976 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1217 10:30:15.194049 140216016906048 run_pretraining.py:259]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1217 10:30:15.194190 140216016906048 run_pretraining.py:259]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1217 10:30:15.194381 140216016906048 run_pretraining.py:259]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1217 10:30:15.194540 140216016906048 run_pretraining.py:259]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1217 10:30:15.194696 140216016906048 run_pretraining.py:259]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1217 10:30:15.194850 140216016906048 run_pretraining.py:259]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1217 10:30:15.195003 140216016906048 run_pretraining.py:259]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 10:30:15.195337 140216016906048 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 10:30:15.195417 139642239878976 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 10:30:15.196763 140216016906048 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1217 10:30:15.204813 140535237592896 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 10:30:15.205127 140535237592896 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1217 10:30:15.212403 140535237592896 run_pretraining.py:259]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1217 10:30:15.212600 140535237592896 run_pretraining.py:259]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1217 10:30:15.212763 140535237592896 run_pretraining.py:259]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1217 10:30:15.212921 140535237592896 run_pretraining.py:259]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1217 10:30:15.213073 140535237592896 run_pretraining.py:259]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1217 10:30:15.213226 140535237592896 run_pretraining.py:259]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1217 10:30:15.213404 140535237592896 run_pretraining.py:259]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 10:30:15.213725 140535237592896 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 10:30:15.215120 140535237592896 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

[yq01-gpu-255-129-15-00.epc.baidu.com:04691] 7 more processes have sent help message help-orte-odls-default.txt / memory not bound
[yq01-gpu-255-129-15-00.epc.baidu.com:04691] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 10:30:17.670929 140601683785536 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 10:30:17.719143 140216016906048 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 10:30:17.723950 140535237592896 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 10:30:17.731451 139917790811968 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 10:30:18.545751 139642239878976 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 10:30:18.731876 140133942306624 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 10:30:18.798189 140452977420096 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 10:30:18.807254 139737462470464 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 10:30:21.562907 140535237592896 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 10:30:21.746251 140601683785536 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 10:30:21.763136 140216016906048 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 10:30:21.833231 139917790811968 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 10:30:21.853855 140535237592896 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 10:30:22.057569 140601683785536 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 10:30:22.068740 140216016906048 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 10:30:22.146931 139917790811968 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 10:30:23.676117 139642239878976 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 10:30:24.017077 139642239878976 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 10:30:25.323406 140133942306624 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 10:30:25.583374 140452977420096 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 10:30:25.764878 140133942306624 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1217 10:30:25.775157 139737462470464 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 10:30:26.007313 140452977420096 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 10:30:26.199621 139737462470464 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I1217 10:30:34.060438 140216016906048 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 10:30:34.665528 140601683785536 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 10:30:34.689985 140535237592896 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 10:30:34.694084 139917790811968 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 10:30:38.740015 139642239878976 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1217 10:30:38.751660 139642239878976 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Done calling model_fn.
I1217 10:30:44.772483 140133942306624 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 10:30:46.390547 140452977420096 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 10:30:46.648205 139737462470464 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Graph was finalized.
I1217 10:30:47.010837 140216016906048 monitored_session.py:240] Graph was finalized.
2020-12-17 10:30:47.035507: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 10:30:47.041434: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x143026a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:47.041487: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 10:30:47.044575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 10:30:47.645959 140601683785536 monitored_session.py:240] Graph was finalized.
2020-12-17 10:30:47.673477: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 10:30:47.673702: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5d4c890 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:47.673875: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 10:30:47.677359: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 10:30:47.917872 139917790811968 monitored_session.py:240] Graph was finalized.
2020-12-17 10:30:47.937693: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 10:30:47.937910: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a0f330 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:47.937959: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
INFO:tensorflow:Graph was finalized.
I1217 10:30:47.939598 140535237592896 monitored_session.py:240] Graph was finalized.
2020-12-17 10:30:47.940974: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 10:30:47.970503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 10:30:47.970714: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x54492b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:47.970758: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 10:30:47.973908: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 10:30:48.214121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:48.238765: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5516be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:48.238797: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 10:30:48.240612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:48.243198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0d.0
2020-12-17 10:30:48.243246: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:48.246736: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:30:48.248348: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 10:30:48.248784: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 10:30:48.251720: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 10:30:48.252456: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 10:30:48.252755: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:30:48.252948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:48.270639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:48.273727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 3
2020-12-17 10:30:48.273774: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:48.429119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:48.433961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18357a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:48.433988: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 10:30:48.435005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:48.439268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0f.0
2020-12-17 10:30:48.439344: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:48.442715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:30:48.444176: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 10:30:48.444577: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 10:30:48.447374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 10:30:48.448031: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 10:30:48.448257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:30:48.448395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:48.465493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:48.474191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 5
2020-12-17 10:30:48.474235: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:48.903084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:48.908423: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x180187c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:48.908456: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 10:30:48.909745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:48.913641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:11.0
2020-12-17 10:30:48.913693: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:48.917107: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:30:48.918618: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 10:30:48.919031: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 10:30:48.921878: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 10:30:48.922609: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 10:30:48.922872: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:30:48.923017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:48.967071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:48.972921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 7
2020-12-17 10:30:48.972976: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:48.981140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:49.001261: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17a37620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:49.001408: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 10:30:49.002975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:49.008316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0b.0
2020-12-17 10:30:49.008375: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:49.012854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:30:49.014914: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 10:30:49.015543: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 10:30:49.020127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 10:30:49.021228: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 10:30:49.021657: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:30:49.021914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:49.028077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:49.035741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 1
2020-12-17 10:30:49.035787: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:49.585095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 10:30:49.585219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      3
2020-12-17 10:30:49.585255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   N
2020-12-17 10:30:49.592329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:49.608113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:49.622287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0d.0, compute capability: 7.0)
2020-12-17 10:30:49.633458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 10:30:49.633494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      5
2020-12-17 10:30:49.633504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 5:   N
2020-12-17 10:30:49.636479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:49.642112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:49.667097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0f.0, compute capability: 7.0)
2020-12-17 10:30:50.161223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 10:30:50.161269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      7
2020-12-17 10:30:50.161289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 7:   N
2020-12-17 10:30:50.161648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:50.175914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:50.177235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:11.0, compute capability: 7.0)
2020-12-17 10:30:50.288116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 10:30:50.288165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      1
2020-12-17 10:30:50.288175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   N
2020-12-17 10:30:50.288531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:50.293459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:50.307602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0b.0, compute capability: 7.0)
INFO:tensorflow:Graph was finalized.
I1217 10:30:51.945732 139642239878976 monitored_session.py:240] Graph was finalized.
2020-12-17 10:30:51.971153: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 10:30:51.971391: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6867200 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:51.971439: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 10:30:51.974578: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 10:30:52.595796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:52.600325: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19088930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:52.600351: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 10:30:52.601493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:52.605835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0a.0
2020-12-17 10:30:52.605890: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:52.609272: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:30:52.610744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 10:30:52.611155: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 10:30:52.613984: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 10:30:52.614693: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 10:30:52.614953: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:30:52.615099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:52.631000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:52.636471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-12-17 10:30:52.636525: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:53.707859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 10:30:53.707913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-12-17 10:30:53.707923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-12-17 10:30:53.708272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:53.709676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:53.711001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0a.0, compute capability: 7.0)
2020-12-17 10:30:57.769885: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:30:57.809243: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:30:57.820775: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:30:57.850834: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Graph was finalized.
I1217 10:30:57.881105 140133942306624 monitored_session.py:240] Graph was finalized.
2020-12-17 10:30:57.892720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 10:30:57.894097: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x660b290 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:57.894129: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 10:30:57.898414: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 10:30:57.961851: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:30:58.014447: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:30:58.290519: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:30:58.341316: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:30:58.438375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:58.440268: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x660f000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:58.440310: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 10:30:58.441042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:58.442343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0c.0
2020-12-17 10:30:58.442396: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:30:58.445857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:30:58.447377: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 10:30:58.447815: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 10:30:58.450659: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 10:30:58.451359: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 10:30:58.451613: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:30:58.451782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:58.453159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:58.454415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 2
2020-12-17 10:30:58.454457: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
INFO:tensorflow:Graph was finalized.
I1217 10:30:59.399428 140452977420096 monitored_session.py:240] Graph was finalized.
2020-12-17 10:30:59.422511: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 10:30:59.422691: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6677660 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:59.422710: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 10:30:59.426024: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 10:30:59.547306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 10:30:59.547360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      2
2020-12-17 10:30:59.547371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   N
2020-12-17 10:30:59.547956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:59.551537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:30:59.554939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0c.0, compute capability: 7.0)
INFO:tensorflow:Graph was finalized.
I1217 10:30:59.709169 139737462470464 monitored_session.py:240] Graph was finalized.
2020-12-17 10:30:59.743509: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-17 10:30:59.743690: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6258710 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:30:59.743710: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-17 10:30:59.747077: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-17 10:31:00.008633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:31:00.010510: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18d39850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:31:00.010539: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 10:31:00.011203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:31:00.012491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0e.0
2020-12-17 10:31:00.012541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:31:00.015952: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:31:00.017481: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 10:31:00.017896: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 10:31:00.020772: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 10:31:00.021501: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 10:31:00.021767: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:31:00.021911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:31:00.025039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:31:00.042227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 4
2020-12-17 10:31:00.042316: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:31:00.282394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:31:00.284312: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x625c480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-17 10:31:00.284345: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-17 10:31:00.285063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:31:00.286363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:10.0
2020-12-17 10:31:00.286416: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:31:00.289950: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:31:00.291497: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 10:31:00.291921: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 10:31:00.294820: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 10:31:00.295531: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 10:31:00.295793: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:31:00.295950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:31:00.297338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:31:00.298594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 6
2020-12-17 10:31:00.298637: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:31:01.127200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 10:31:01.127265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      4
2020-12-17 10:31:01.127286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 4:   N
2020-12-17 10:31:01.127691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:31:01.130536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:31:01.133445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0e.0, compute capability: 7.0)
2020-12-17 10:31:01.407145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 10:31:01.407201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      6
2020-12-17 10:31:01.407212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 6:   N
2020-12-17 10:31:01.408653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:31:01.412160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:31:01.427659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:10.0, compute capability: 7.0)
2020-12-17 10:31:02.188589: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:02.237341: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:03.875115: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 10:31:04.092875: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 10:31:04.132465: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 10:31:04.507597: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 10:31:08.191872: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:08.218879: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-17 10:31:08.236639: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:09.639644: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:09.692056: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:10.145288: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:10.202937: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:12.021058: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:12.044343: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:12.273994: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:12.305007: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:12.336872: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:12.347297: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:12.681044: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:12.691567: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1217 10:31:14.089693 140601683785536 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 10:31:14.408081 140216016906048 session_manager.py:500] Running local_init_op.
2020-12-17 10:31:14.410634: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Running local_init_op.
I1217 10:31:14.412576 139917790811968 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 10:31:14.679854 140535237592896 session_manager.py:500] Running local_init_op.
2020-12-17 10:31:15.441208: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:15.441504: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:15.677496: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Done running local_init_op.
I1217 10:31:15.773529 140601683785536 session_manager.py:502] Done running local_init_op.
2020-12-17 10:31:15.798971: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:15.799243: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:15.807941: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:15.808207: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:16.067767: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:16.068034: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1217 10:31:16.143401 139917790811968 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 10:31:16.152448 140216016906048 session_manager.py:502] Done running local_init_op.
2020-12-17 10:31:16.251000: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Done running local_init_op.
I1217 10:31:16.399493 140535237592896 session_manager.py:502] Done running local_init_op.
2020-12-17 10:31:16.546937: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:16.555833: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:17.593557: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:17.616670: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:17.969171: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:17.992715: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:18.036017: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:18.060618: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:18.207547: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:18.217218: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1217 10:31:18.409795 139642239878976 session_manager.py:500] Running local_init_op.
2020-12-17 10:31:19.793748: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:19.794016: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1217 10:31:20.105995 139642239878976 session_manager.py:502] Done running local_init_op.
2020-12-17 10:31:20.854058: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:20.854496: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:20.860244: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:20.862493: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:20.865632: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:21.280749: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:21.281167: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:21.287132: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:21.289427: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:21.305630: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:21.370425: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:21.370864: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:21.387009: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:21.389428: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:21.392620: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:21.406520: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:21.406902: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:21.412595: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:21.427036: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:21.430229: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:21.984559: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:21.994065: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:22.442188: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:22.477409: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:23.512787: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:23.549937: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:23.681287: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:23.704886: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:24.038535: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:24.090459: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:24.092343: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:24.124032: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:24.136344: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:24.168005: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:24.218215: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:24.241395: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1217 10:31:24.366996 140133942306624 session_manager.py:500] Running local_init_op.
2020-12-17 10:31:25.221946: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:25.222301: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1217 10:31:25.587454 140452977420096 session_manager.py:500] Running local_init_op.
2020-12-17 10:31:25.730990: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:25.731263: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1217 10:31:26.050193 140133942306624 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 10:31:26.169111 139737462470464 session_manager.py:500] Running local_init_op.
2020-12-17 10:31:26.955474: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:26.955739: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1217 10:31:27.268387 140452977420096 session_manager.py:502] Done running local_init_op.
2020-12-17 10:31:27.538524: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:27.538795: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:27.787678: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
INFO:tensorflow:Done running local_init_op.
I1217 10:31:27.792320 139737462470464 session_manager.py:502] Done running local_init_op.
2020-12-17 10:31:27.796467: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:28.525752: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:28.536798: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:28.702601: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:28.715245: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:29.579029: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:29.579463: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:29.585465: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:29.587952: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:29.591345: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:30.560616: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:30.561020: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:30.566785: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:30.569155: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:30.572274: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:30.631887: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:30.632317: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:30.638212: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:30.640560: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:30.643713: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:31.084750: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:31.116531: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:32.019189: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:32.038403: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:32.286125: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:32.310166: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1/model.ckpt.
I1217 10:31:40.109155 139642239878976 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1/model.ckpt.
2020-12-17 10:31:41.179387: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:41.189682: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:48.935880: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:48.936300: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:48.942269: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:48.944518: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:48.947736: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:31:50.214005: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:50.233638: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:146: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W1217 10:31:53.753203 139642239878976 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:146: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2020-12-17 10:31:55.231268: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:31:55.231598: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:32:26.416449: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:32:26.483030: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:32:26.558331: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:32:26.674210: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:32:26.691156: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:32:26.694035: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:32:26.772821: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:32:26.837085: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:32:26.849618: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:32:26.872387: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:32:26.969436: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:32:26.971579: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:32:27.142975: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:32:27.160300: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:32:27.796029: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:32:28.021540: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:32:50.097496: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:32:51.503785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:32:51.862953: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:32:52.855420: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:32:52.909062: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:32:53.308224: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:32:53.376191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:32:53.441082: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:32:53.490517: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:32:53.645841: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:32:54.621580: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:32:54.656854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:32:55.231801: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:32:55.279464: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:32:55.304753: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:32:55.407527: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:34:03.934217: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 10:34:06.843236: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 10:34:07.589444: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 10:34:07.706072: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 10:34:08.178644: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 10:34:08.415523: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 10:34:08.971726: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2020-12-17 10:34:09.224386: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
INFO:tensorflow:loss = 11.120217, step = 0
I1217 10:34:12.814344 139642239878976 basic_session_run_hooks.py:262] loss = 11.120217, step = 0
2020-12-17 10:34:14.278538: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:14.278912: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:34:14.316512: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:14.316872: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:34:14.344190: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:14.344571: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:34:14.344598: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:14.344944: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:34:14.345911: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:14.346270: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:34:14.371868: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:14.372228: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:34:14.390240: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:14.390622: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:loss = 11.131231, step = 0
I1217 10:34:14.668299 140535237592896 basic_session_run_hooks.py:262] loss = 11.131231, step = 0
INFO:tensorflow:loss = 11.124036, step = 0
I1217 10:34:14.705488 140601683785536 basic_session_run_hooks.py:262] loss = 11.124036, step = 0
INFO:tensorflow:loss = 11.110416, step = 0
I1217 10:34:14.725436 139737462470464 basic_session_run_hooks.py:262] loss = 11.110416, step = 0
INFO:tensorflow:loss = 11.095195, step = 0
I1217 10:34:14.735417 140216016906048 basic_session_run_hooks.py:262] loss = 11.095195, step = 0
INFO:tensorflow:loss = 11.122387, step = 0
I1217 10:34:14.737445 140452977420096 basic_session_run_hooks.py:262] loss = 11.122387, step = 0
INFO:tensorflow:loss = 11.106051, step = 0
I1217 10:34:14.756378 139917790811968 basic_session_run_hooks.py:262] loss = 11.106051, step = 0
INFO:tensorflow:loss = 11.087748, step = 0
I1217 10:34:14.794685 140133942306624 basic_session_run_hooks.py:262] loss = 11.087748, step = 0
2020-12-17 10:34:46.855475: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:47.349118: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:34:48.155644: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:48.189756: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:48.230569: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:48.507237: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:48.541563: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:48.648090: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:34:48.681682: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:34:48.731622: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:34:48.763729: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:48.983098: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:34:49.028155: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:34:49.265844: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-17 10:34:49.370936: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:34:49.878236: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.221765 140601683785536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.221731 139917790811968 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.221767 140535237592896 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.222864 139737462470464 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.226175 139642239878976 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.233376 140216016906048 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.234391 140452977420096 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.236653 140133942306624 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.401760 140601683785536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.401717 140452977420096 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.401769 140535237592896 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.401758 139737462470464 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.401763 140216016906048 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.401789 139917790811968 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.402223 139642239878976 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.406631 140133942306624 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.563095 139737462470464 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.563073 140601683785536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.563072 139917790811968 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.563085 140452977420096 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.563081 140216016906048 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.563096 140535237592896 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.563161 140133942306624 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.563440 139642239878976 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.712867 140216016906048 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.712867 140133942306624 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.712862 139737462470464 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.712862 140601683785536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.712844 139917790811968 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.712886 140535237592896 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.713205 139642239878976 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.713110 140452977420096 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.865255 139917790811968 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.865260 140601683785536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.865309 140216016906048 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.865303 140535237592896 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.865298 139737462470464 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.865258 140133942306624 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.865334 140452977420096 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 10:36:28.865866 139642239878976 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 10:37:08.294216 - Iteration: 1  throughput_train : 216.175 seq/s mlm_loss : 10.4171  nsp_loss : 0.6957  total_loss : 11.1128  avg_loss_step : 11.1044  learning_rate : 0.0  loss_scaler : 4294967296
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 10:37:29.450540 - Iteration: 1  throughput_train : 3198.091 seq/s mlm_loss : 10.3931  nsp_loss : 0.6891  total_loss : 11.0821  avg_loss_step : 11.1067  learning_rate : 0.0  loss_scaler : 2147483648
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 10:37:50.334809 - Iteration: 1  throughput_train : 3239.519 seq/s mlm_loss : 10.3913  nsp_loss : 0.6954  total_loss : 11.0866  avg_loss_step : 11.1058  learning_rate : 0.0  loss_scaler : 1073741824
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 10:38:11.533963 - Iteration: 1  throughput_train : 3192.418 seq/s mlm_loss : 10.4378  nsp_loss : 0.6826  total_loss : 11.1204  avg_loss_step : 11.1062  learning_rate : 0.0  loss_scaler : 536870912
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 10:38:32.698317 - Iteration: 1  throughput_train : 3196.920 seq/s mlm_loss : 10.4155  nsp_loss : 0.7005  total_loss : 11.1159  avg_loss_step : 11.1071  learning_rate : 0.0  loss_scaler : 268435456
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 10:38:53.839674 - Iteration: 1  throughput_train : 3200.145 seq/s mlm_loss : 10.4107  nsp_loss : 0.6925  total_loss : 11.1032  avg_loss_step : 11.1040  learning_rate : 0.0  loss_scaler : 134217728
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 10:39:40.914358 - Iteration: 1  throughput_train : 1436.360 seq/s mlm_loss : 10.4215  nsp_loss : 0.7007  total_loss : 11.1223  avg_loss_step : 11.1061  learning_rate : 0.0  loss_scaler : 67108864
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 10:40:02.421721 - Iteration: 2  throughput_train : 3145.615 seq/s mlm_loss : 10.4052  nsp_loss : 0.6941  total_loss : 11.0993  avg_loss_step : 11.1035  learning_rate : 0.0  loss_scaler : 33554432
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 10:41:19.153769 - Iteration: 3  throughput_train : 881.032 seq/s mlm_loss : 10.4059  nsp_loss : 0.6843  total_loss : 11.0902  avg_loss_step : 11.1054  learning_rate : 3e-06  loss_scaler : 16777216
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 10:41:42.334470 - Iteration: 4  throughput_train : 2918.298 seq/s mlm_loss : 10.4085  nsp_loss : 0.7002  total_loss : 11.1088  avg_loss_step : 11.1024  learning_rate : 6e-06  loss_scaler : 16777216
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 10:42:04.489710 - Iteration: 5  throughput_train : 3053.625 seq/s mlm_loss : 10.4145  nsp_loss : 0.6918  total_loss : 11.1063  avg_loss_step : 11.1019  learning_rate : 9e-06  loss_scaler : 16777216
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2020-12-17 10:42:26.667587 - Iteration: 6  throughput_train : 3050.393 seq/s mlm_loss : 10.4044  nsp_loss : 0.6816  total_loss : 11.0859  avg_loss_step : 11.0992  learning_rate : 1.2e-05  loss_scaler : 16777216
DLL 2020-12-17 10:42:48.969609 - Iteration: 7  throughput_train : 3033.395 seq/s mlm_loss : 10.4340  nsp_loss : 0.6952  total_loss : 11.1292  avg_loss_step : 11.0929  learning_rate : 1.50000005e-05  loss_scaler : 16777216
DLL 2020-12-17 10:43:11.248259 - Iteration: 8  throughput_train : 3036.812 seq/s mlm_loss : 10.3843  nsp_loss : 0.6967  total_loss : 11.0810  avg_loss_step : 11.0909  learning_rate : 1.8e-05  loss_scaler : 16777216
DLL 2020-12-17 10:43:33.432254 - Iteration: 9  throughput_train : 3050.143 seq/s mlm_loss : 10.3880  nsp_loss : 0.6708  total_loss : 11.0588  avg_loss_step : 11.0836  learning_rate : 2.1e-05  loss_scaler : 16777216
DLL 2020-12-17 10:43:55.738077 - Iteration: 10  throughput_train : 3032.788 seq/s mlm_loss : 10.4073  nsp_loss : 0.6930  total_loss : 11.1003  avg_loss_step : 11.0785  learning_rate : 2.4e-05  loss_scaler : 16777216
DLL 2020-12-17 10:44:17.914981 - Iteration: 11  throughput_train : 3050.930 seq/s mlm_loss : 10.3526  nsp_loss : 0.6908  total_loss : 11.0434  avg_loss_step : 11.0689  learning_rate : 2.7000002e-05  loss_scaler : 16777216
DLL 2020-12-17 10:44:40.125368 - Iteration: 12  throughput_train : 3046.156 seq/s mlm_loss : 10.3900  nsp_loss : 0.6950  total_loss : 11.0850  avg_loss_step : 11.0627  learning_rate : 3.0000001e-05  loss_scaler : 16777216
DLL 2020-12-17 10:45:02.389587 - Iteration: 13  throughput_train : 3038.550 seq/s mlm_loss : 10.4045  nsp_loss : 0.6830  total_loss : 11.0876  avg_loss_step : 11.0530  learning_rate : 3.3e-05  loss_scaler : 16777216
DLL 2020-12-17 10:45:24.581747 - Iteration: 14  throughput_train : 3048.584 seq/s mlm_loss : 10.3540  nsp_loss : 0.6991  total_loss : 11.0531  avg_loss_step : 11.0421  learning_rate : 3.6e-05  loss_scaler : 16777216
DLL 2020-12-17 10:45:46.863306 - Iteration: 15  throughput_train : 3036.323 seq/s mlm_loss : 10.3586  nsp_loss : 0.7009  total_loss : 11.0595  avg_loss_step : 11.0334  learning_rate : 3.9000002e-05  loss_scaler : 16777216
DLL 2020-12-17 10:46:09.048564 - Iteration: 16  throughput_train : 3049.624 seq/s mlm_loss : 10.3212  nsp_loss : 0.6753  total_loss : 10.9965  avg_loss_step : 11.0213  learning_rate : 4.2e-05  loss_scaler : 16777216
DLL 2020-12-17 10:46:31.445803 - Iteration: 17  throughput_train : 3020.674 seq/s mlm_loss : 10.3268  nsp_loss : 0.6644  total_loss : 10.9912  avg_loss_step : 11.0110  learning_rate : 4.5e-05  loss_scaler : 16777216
DLL 2020-12-17 10:46:53.578871 - Iteration: 18  throughput_train : 3056.866 seq/s mlm_loss : 10.3093  nsp_loss : 0.6488  total_loss : 10.9580  avg_loss_step : 10.9984  learning_rate : 4.8e-05  loss_scaler : 16777216
DLL 2020-12-17 10:47:15.847525 - Iteration: 19  throughput_train : 3037.986 seq/s mlm_loss : 10.3064  nsp_loss : 0.7102  total_loss : 11.0166  avg_loss_step : 10.9884  learning_rate : 5.1000003e-05  loss_scaler : 16777216
DLL 2020-12-17 10:47:38.112944 - Iteration: 20  throughput_train : 3038.501 seq/s mlm_loss : 10.2986  nsp_loss : 0.6710  total_loss : 10.9696  avg_loss_step : 10.9681  learning_rate : 5.4000004e-05  loss_scaler : 16777216
DLL 2020-12-17 10:48:00.390362 - Iteration: 21  throughput_train : 3036.874 seq/s mlm_loss : 10.2927  nsp_loss : 0.6865  total_loss : 10.9793  avg_loss_step : 10.9591  learning_rate : 5.7e-05  loss_scaler : 16777216
DLL 2020-12-17 10:48:22.671889 - Iteration: 22  throughput_train : 3036.248 seq/s mlm_loss : 10.2438  nsp_loss : 0.6313  total_loss : 10.8751  avg_loss_step : 10.9354  learning_rate : 6.0000002e-05  loss_scaler : 16777216
DLL 2020-12-17 10:48:44.898251 - Iteration: 23  throughput_train : 3043.864 seq/s mlm_loss : 10.2287  nsp_loss : 0.6750  total_loss : 10.9037  avg_loss_step : 10.9204  learning_rate : 6.3e-05  loss_scaler : 16777216
DLL 2020-12-17 10:49:07.332067 - Iteration: 24  throughput_train : 3015.500 seq/s mlm_loss : 10.1875  nsp_loss : 0.6720  total_loss : 10.8595  avg_loss_step : 10.9017  learning_rate : 6.6e-05  loss_scaler : 16777216
DLL 2020-12-17 10:49:29.676552 - Iteration: 25  throughput_train : 3027.710 seq/s mlm_loss : 10.2067  nsp_loss : 0.6923  total_loss : 10.8990  avg_loss_step : 10.8858  learning_rate : 6.9e-05  loss_scaler : 16777216
DLL 2020-12-17 10:49:51.928748 - Iteration: 26  throughput_train : 3040.230 seq/s mlm_loss : 10.2049  nsp_loss : 0.6883  total_loss : 10.8932  avg_loss_step : 10.8637  learning_rate : 7.2e-05  loss_scaler : 16777216
DLL 2020-12-17 10:50:14.203763 - Iteration: 27  throughput_train : 3037.210 seq/s mlm_loss : 10.1811  nsp_loss : 0.7165  total_loss : 10.8976  avg_loss_step : 10.8542  learning_rate : 7.5e-05  loss_scaler : 16777216
DLL 2020-12-17 10:50:36.347921 - Iteration: 28  throughput_train : 3055.015 seq/s mlm_loss : 10.1412  nsp_loss : 0.6768  total_loss : 10.8181  avg_loss_step : 10.8306  learning_rate : 7.8000005e-05  loss_scaler : 16777216
DLL 2020-12-17 10:50:58.632657 - Iteration: 29  throughput_train : 3035.738 seq/s mlm_loss : 10.1029  nsp_loss : 0.6726  total_loss : 10.7755  avg_loss_step : 10.8084  learning_rate : 8.1000006e-05  loss_scaler : 16777216
DLL 2020-12-17 10:51:20.829707 - Iteration: 30  throughput_train : 3047.839 seq/s mlm_loss : 10.0823  nsp_loss : 0.6946  total_loss : 10.7768  avg_loss_step : 10.7890  learning_rate : 8.4e-05  loss_scaler : 16777216
DLL 2020-12-17 10:51:43.173567 - Iteration: 31  throughput_train : 3027.691 seq/s mlm_loss : 10.0756  nsp_loss : 0.6471  total_loss : 10.7227  avg_loss_step : 10.7711  learning_rate : 8.7e-05  loss_scaler : 16777216
DLL 2020-12-17 10:52:05.489930 - Iteration: 32  throughput_train : 3031.450 seq/s mlm_loss : 10.0893  nsp_loss : 0.6711  total_loss : 10.7604  avg_loss_step : 10.7486  learning_rate : 9e-05  loss_scaler : 16777216
DLL 2020-12-17 10:52:27.755103 - Iteration: 33  throughput_train : 3038.838 seq/s mlm_loss : 10.0414  nsp_loss : 0.6682  total_loss : 10.7096  avg_loss_step : 10.7215  learning_rate : 9.3e-05  loss_scaler : 16777216
DLL 2020-12-17 10:52:50.078415 - Iteration: 34  throughput_train : 3030.479 seq/s mlm_loss : 10.0264  nsp_loss : 0.6774  total_loss : 10.7038  avg_loss_step : 10.7082  learning_rate : 9.6e-05  loss_scaler : 16777216
DLL 2020-12-17 10:53:12.440471 - Iteration: 35  throughput_train : 3025.307 seq/s mlm_loss : 9.9902  nsp_loss : 0.6546  total_loss : 10.6448  avg_loss_step : 10.6826  learning_rate : 9.9000004e-05  loss_scaler : 16777216
DLL 2020-12-17 10:53:34.841100 - Iteration: 36  throughput_train : 3020.089 seq/s mlm_loss : 10.0319  nsp_loss : 0.6834  total_loss : 10.7153  avg_loss_step : 10.6641  learning_rate : 0.000102000005  loss_scaler : 16777216
DLL 2020-12-17 10:53:57.064392 - Iteration: 37  throughput_train : 3044.120 seq/s mlm_loss : 9.9181  nsp_loss : 0.7107  total_loss : 10.6288  avg_loss_step : 10.6400  learning_rate : 0.00010500001  loss_scaler : 16777216
DLL 2020-12-17 10:54:19.477967 - Iteration: 38  throughput_train : 3018.275 seq/s mlm_loss : 9.9453  nsp_loss : 0.6960  total_loss : 10.6413  avg_loss_step : 10.6146  learning_rate : 0.00010800001  loss_scaler : 16777216
DLL 2020-12-17 10:54:41.830778 - Iteration: 39  throughput_train : 3026.562 seq/s mlm_loss : 9.9035  nsp_loss : 0.6800  total_loss : 10.5835  avg_loss_step : 10.5949  learning_rate : 0.000111  loss_scaler : 16777216
DLL 2020-12-17 10:55:04.204717 - Iteration: 40  throughput_train : 3023.872 seq/s mlm_loss : 9.8998  nsp_loss : 0.6242  total_loss : 10.5240  avg_loss_step : 10.5760  learning_rate : 0.000114  loss_scaler : 16777216
DLL 2020-12-17 10:55:26.298086 - Iteration: 41  throughput_train : 3062.154 seq/s mlm_loss : 9.8238  nsp_loss : 0.7133  total_loss : 10.5371  avg_loss_step : 10.5541  learning_rate : 0.000117  loss_scaler : 16777216
DLL 2020-12-17 10:55:48.485984 - Iteration: 42  throughput_train : 3049.089 seq/s mlm_loss : 9.8691  nsp_loss : 0.6738  total_loss : 10.5429  avg_loss_step : 10.5383  learning_rate : 0.000120000004  loss_scaler : 16777216
DLL 2020-12-17 10:56:10.897112 - Iteration: 43  throughput_train : 3018.803 seq/s mlm_loss : 9.9015  nsp_loss : 0.6980  total_loss : 10.5995  avg_loss_step : 10.5147  learning_rate : 0.000123  loss_scaler : 16777216
DLL 2020-12-17 10:56:33.019400 - Iteration: 44  throughput_train : 3058.182 seq/s mlm_loss : 9.7624  nsp_loss : 0.6881  total_loss : 10.4505  avg_loss_step : 10.4909  learning_rate : 0.000126  loss_scaler : 16777216
DLL 2020-12-17 10:56:55.284536 - Iteration: 45  throughput_train : 3038.418 seq/s mlm_loss : 9.8326  nsp_loss : 0.6944  total_loss : 10.5269  avg_loss_step : 10.4741  learning_rate : 0.00012900001  loss_scaler : 16777216
DLL 2020-12-17 10:57:17.574050 - Iteration: 46  throughput_train : 3035.188 seq/s mlm_loss : 9.8287  nsp_loss : 0.6979  total_loss : 10.5266  avg_loss_step : 10.4624  learning_rate : 0.000132  loss_scaler : 16777216
DLL 2020-12-17 10:57:39.799716 - Iteration: 47  throughput_train : 3043.983 seq/s mlm_loss : 9.7681  nsp_loss : 0.6783  total_loss : 10.4464  avg_loss_step : 10.4310  learning_rate : 0.00013500001  loss_scaler : 16777216
DLL 2020-12-17 10:58:02.177376 - Iteration: 48  throughput_train : 3023.100 seq/s mlm_loss : 9.7336  nsp_loss : 0.6659  total_loss : 10.3995  avg_loss_step : 10.4211  learning_rate : 0.000138  loss_scaler : 16777216
DLL 2020-12-17 10:58:24.456080 - Iteration: 49  throughput_train : 3036.613 seq/s mlm_loss : 9.7351  nsp_loss : 0.6858  total_loss : 10.4209  avg_loss_step : 10.4070  learning_rate : 0.00014100001  loss_scaler : 16777216
DLL 2020-12-17 10:58:46.678206 - Iteration: 50  throughput_train : 3044.369 seq/s mlm_loss : 9.6594  nsp_loss : 0.6749  total_loss : 10.3343  avg_loss_step : 10.3755  learning_rate : 0.000144  loss_scaler : 16777216
DLL 2020-12-17 10:59:09.048871 - Iteration: 51  throughput_train : 3046.368 seq/s mlm_loss : 9.7370  nsp_loss : 0.6764  total_loss : 10.4135  avg_loss_step : 10.3461  learning_rate : 0.000147  loss_scaler : 16777216
INFO:tensorflow:Saving checkpoints for 50 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1/model.ckpt.
I1217 10:59:09.050466 139642239878976 basic_session_run_hooks.py:606] Saving checkpoints for 50 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 10.37275.
I1217 10:59:11.006686 140601683785536 estimator.py:371] Loss for final step: 10.37275.
INFO:tensorflow:Loss for final step: 10.342961.
I1217 10:59:11.034238 140216016906048 estimator.py:371] Loss for final step: 10.342961.
INFO:tensorflow:Loss for final step: 10.359704.
I1217 10:59:11.041045 140452977420096 estimator.py:371] Loss for final step: 10.359704.
INFO:tensorflow:Loss for final step: 10.361067.
I1217 10:59:11.047235 139737462470464 estimator.py:371] Loss for final step: 10.361067.
INFO:tensorflow:Loss for final step: 10.352114.
I1217 10:59:11.055027 139917790811968 estimator.py:371] Loss for final step: 10.352114.
INFO:tensorflow:Loss for final step: 10.358596.
I1217 10:59:11.132863 140535237592896 estimator.py:371] Loss for final step: 10.358596.
INFO:tensorflow:Loss for final step: 10.345195.
I1217 10:59:11.209705 140133942306624 estimator.py:371] Loss for final step: 10.345195.
INFO:tensorflow:Loss for final step: 10.413469.
I1217 10:59:15.769023 139642239878976 estimator.py:371] Loss for final step: 10.413469.
INFO:tensorflow:-----------------------------
I1217 10:59:15.770410 139642239878976 run_pretraining.py:642] -----------------------------
INFO:tensorflow:Total Training Time = 1741.09 for Sentences = 3379200
I1217 10:59:15.770653 139642239878976 run_pretraining.py:644] Total Training Time = 1741.09 for Sentences = 3379200
INFO:tensorflow:Total Training Time W/O Overhead = 1001.19 for Sentences = 2568192
I1217 10:59:15.770731 139642239878976 run_pretraining.py:646] Total Training Time W/O Overhead = 1001.19 for Sentences = 2568192
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 1940.85
I1217 10:59:15.770786 139642239878976 run_pretraining.py:647] Throughput Average (sentences/sec) with overhead = 1940.85
INFO:tensorflow:Throughput Average (sentences/sec) = 2565.13
I1217 10:59:15.770861 139642239878976 run_pretraining.py:648] Throughput Average (sentences/sec) = 2565.13
DLL 2020-12-17 10:59:15.770925 -  throughput_train : 2565.134 seq/s
INFO:tensorflow:-----------------------------
I1217 10:59:15.771074 139642239878976 run_pretraining.py:650] -----------------------------
INFO:tensorflow:***** Running evaluation *****
I1217 10:59:15.771162 139642239878976 run_pretraining.py:653] ***** Running evaluation *****
INFO:tensorflow:  Batch size = 8
I1217 10:59:15.771229 139642239878976 run_pretraining.py:654]   Batch size = 8
INFO:tensorflow:Calling model_fn.
I1217 10:59:15.815696 139642239878976 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 10:59:15.815930 139642239878976 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (?, 128)
I1217 10:59:15.816044 139642239878976 run_pretraining.py:259]   name = input_ids, shape = (?, 128)
INFO:tensorflow:  name = input_mask, shape = (?, 128)
I1217 10:59:15.816132 139642239878976 run_pretraining.py:259]   name = input_mask, shape = (?, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (?, 20)
I1217 10:59:15.816212 139642239878976 run_pretraining.py:259]   name = masked_lm_ids, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (?, 20)
I1217 10:59:15.816303 139642239878976 run_pretraining.py:259]   name = masked_lm_positions, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (?, 20)
I1217 10:59:15.816384 139642239878976 run_pretraining.py:259]   name = masked_lm_weights, shape = (?, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (?, 1)
I1217 10:59:15.816466 139642239878976 run_pretraining.py:259]   name = next_sentence_labels, shape = (?, 1)
INFO:tensorflow:  name = segment_ids, shape = (?, 128)
I1217 10:59:15.816540 139642239878976 run_pretraining.py:259]   name = segment_ids, shape = (?, 128)
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:337: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

W1217 10:59:17.615780 139642239878976 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:337: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:341: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

W1217 10:59:17.664038 139642239878976 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:341: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

INFO:tensorflow:Done calling model_fn.
I1217 10:59:17.742259 139642239878976 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-12-17T10:59:17Z
I1217 10:59:17.762926 139642239878976 evaluation.py:255] Starting evaluation at 2020-12-17T10:59:17Z
INFO:tensorflow:Graph was finalized.
I1217 10:59:18.129750 139642239878976 monitored_session.py:240] Graph was finalized.
2020-12-17 10:59:18.130932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:59:18.131981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0a.0
2020-12-17 10:59:18.132072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 10:59:18.132205: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 10:59:18.132266: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 10:59:18.132328: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 10:59:18.132374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 10:59:18.132426: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 10:59:18.132472: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 10:59:18.132609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:59:18.133652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:59:18.134598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-12-17 10:59:18.134697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 10:59:18.134731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-12-17 10:59:18.134762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-12-17 10:59:18.134912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:59:18.135933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 10:59:18.136897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0a.0, compute capability: 7.0)
INFO:tensorflow:Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1/model.ckpt-50
I1217 10:59:18.138101 139642239878976 saver.py:1284] Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1/model.ckpt-50
2020-12-17 10:59:18.319648: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:59:18.323057: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:59:19.048753: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:59:19.050964: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1217 10:59:19.271178 139642239878976 session_manager.py:500] Running local_init_op.
2020-12-17 10:59:19.323053: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:59:19.323578: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1217 10:59:19.526395 139642239878976 session_manager.py:502] Done running local_init_op.
2020-12-17 10:59:19.626085: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:59:19.628372: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:59:19.912924: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:59:19.913435: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:59:19.918885: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:59:19.921861: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-17 10:59:20.226221: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:59:20.238539: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 2026
Recognized nodes available for conversion: 1004
Total nodes converted: 276
Total FP16 Cast ops used (excluding Const and Variable casts): 39
Whitelisted nodes converted: 100
Blacklisted nodes blocking conversion: 139
Nodes blocked from conversion by blacklisted nodes: 239

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


INFO:tensorflow:Evaluation [10/100]
I1217 10:59:27.408342 139642239878976 evaluation.py:167] Evaluation [10/100]
INFO:tensorflow:Evaluation [20/100]
I1217 10:59:27.532177 139642239878976 evaluation.py:167] Evaluation [20/100]
INFO:tensorflow:Evaluation [30/100]
I1217 10:59:27.654997 139642239878976 evaluation.py:167] Evaluation [30/100]
INFO:tensorflow:Evaluation [40/100]
I1217 10:59:27.777929 139642239878976 evaluation.py:167] Evaluation [40/100]
INFO:tensorflow:Evaluation [50/100]
I1217 10:59:27.900650 139642239878976 evaluation.py:167] Evaluation [50/100]
INFO:tensorflow:Evaluation [60/100]
I1217 10:59:28.023565 139642239878976 evaluation.py:167] Evaluation [60/100]
INFO:tensorflow:Evaluation [70/100]
I1217 10:59:28.145874 139642239878976 evaluation.py:167] Evaluation [70/100]
INFO:tensorflow:Evaluation [80/100]
I1217 10:59:28.283777 139642239878976 evaluation.py:167] Evaluation [80/100]
INFO:tensorflow:Evaluation [90/100]
I1217 10:59:28.406873 139642239878976 evaluation.py:167] Evaluation [90/100]
INFO:tensorflow:Evaluation [100/100]
I1217 10:59:28.528854 139642239878976 evaluation.py:167] Evaluation [100/100]
2020-12-17 10:59:28.600022: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-17 10:59:28.600573: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Finished evaluation at 2020-12-17-10:59:28
I1217 10:59:28.904317 139642239878976 evaluation.py:275] Finished evaluation at 2020-12-17-10:59:28
INFO:tensorflow:Saving dict for global step 50: global_step = 50, loss = 10.326613, masked_lm_accuracy = 0.052995395, masked_lm_loss = 9.629124, next_sentence_accuracy = 0.53, next_sentence_loss = 0.6970051
I1217 10:59:28.905126 139642239878976 estimator.py:2049] Saving dict for global step 50: global_step = 50, loss = 10.326613, masked_lm_accuracy = 0.052995395, masked_lm_loss = 9.629124, next_sentence_accuracy = 0.53, next_sentence_loss = 0.6970051
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1/model.ckpt-50
I1217 10:59:29.295395 139642239878976 estimator.py:2109] Saving 'checkpoint_path' summary for global step 50: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_201217103010/phase_1/model.ckpt-50
INFO:tensorflow:-----------------------------
I1217 10:59:29.296723 139642239878976 run_pretraining.py:682] -----------------------------
INFO:tensorflow:Total Inference Time = 13.52 for Sentences = 800
I1217 10:59:29.296964 139642239878976 run_pretraining.py:684] Total Inference Time = 13.52 for Sentences = 800
INFO:tensorflow:Total Inference Time W/O Overhead = 1.23 for Sentences = 792
I1217 10:59:29.297105 139642239878976 run_pretraining.py:686] Total Inference Time W/O Overhead = 1.23 for Sentences = 792
INFO:tensorflow:Summary Inference Statistics on EVAL set
I1217 10:59:29.297226 139642239878976 run_pretraining.py:687] Summary Inference Statistics on EVAL set
INFO:tensorflow:Batch size = 8
I1217 10:59:29.297376 139642239878976 run_pretraining.py:688] Batch size = 8
INFO:tensorflow:Sequence Length = 128
I1217 10:59:29.297569 139642239878976 run_pretraining.py:689] Sequence Length = 128
INFO:tensorflow:Precision = fp16
I1217 10:59:29.297694 139642239878976 run_pretraining.py:690] Precision = fp16
INFO:tensorflow:Throughput Average (sentences/sec) = 645.12
I1217 10:59:29.297812 139642239878976 run_pretraining.py:691] Throughput Average (sentences/sec) = 645.12
DLL 2020-12-17 10:59:29.297956 -  throughput_val : 645.1242775851813
INFO:tensorflow:-----------------------------
I1217 10:59:29.298190 139642239878976 run_pretraining.py:693] -----------------------------
INFO:tensorflow:***** Eval results *****
I1217 10:59:29.298425 139642239878976 run_pretraining.py:697] ***** Eval results *****
INFO:tensorflow:  global_step = 50
I1217 10:59:29.298564 139642239878976 run_pretraining.py:699]   global_step = 50
INFO:tensorflow:  loss = 10.326613
I1217 10:59:29.298788 139642239878976 run_pretraining.py:699]   loss = 10.326613
INFO:tensorflow:  masked_lm_accuracy = 0.052995395
I1217 10:59:29.298930 139642239878976 run_pretraining.py:699]   masked_lm_accuracy = 0.052995395
INFO:tensorflow:  masked_lm_loss = 9.629124
I1217 10:59:29.299055 139642239878976 run_pretraining.py:699]   masked_lm_loss = 9.629124
INFO:tensorflow:  next_sentence_accuracy = 0.53
I1217 10:59:29.299176 139642239878976 run_pretraining.py:699]   next_sentence_accuracy = 0.53
INFO:tensorflow:  next_sentence_loss = 0.6970051
I1217 10:59:29.299321 139642239878976 run_pretraining.py:699]   next_sentence_loss = 0.6970051
